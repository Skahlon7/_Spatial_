{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urgPju-ZH8mX"
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EN1-FZodOuPl"
   },
   "outputs": [],
   "source": [
    "# Import the Tokenizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5Qwn_7FSXW-"
   },
   "source": [
    "## Write some sentences\n",
    "\n",
    "Feel free to change and add sentences as you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RMiq8BpWVVRa"
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'My favorite food is ice cream',\n",
    "    'do you like ice cream too?',\n",
    "    'My dog likes ice cream!',\n",
    "    \"your favorite flavor of icecream is chocolate\",\n",
    "    \"chocolate isn't good for dogs\",\n",
    "    \"your dog, your cat, and your parrot prefer broccoli\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wz845OtfRBCM"
   },
   "source": [
    "## Tokenize the words\n",
    "\n",
    "The first step to preparing text to be used in a machine learning model is to tokenize the text, in other words, to generate numbers for the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZHTK1DAlQ1zO"
   },
   "outputs": [],
   "source": [
    "# Optionally set the max number of words to tokenize.\n",
    "# The out of vocabulary (OOV) token represents words that are not in the index.\n",
    "# Call fit_on_text() on the tokenizer to generate unique numbers for each word\n",
    "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mylv-WuiRzd0"
   },
   "source": [
    "## View the word index\n",
    "After you tokenize the text, the tokenizer has a word index that contains key-value pairs for all the words and their numbers.\n",
    "\n",
    "The word is the key, and the number is the value.\n",
    "\n",
    "Notice that the OOV token is the first entry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kX4VvsLySC7Z",
    "outputId": "e86e2661-a8bb-4164-cc09-5654dcfbedc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n"
     ]
    }
   ],
   "source": [
    "# Examine the word index\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JXKrGxsIVtLo",
    "outputId": "f39a071c-4bd9-4f43-b44a-e6290734ea67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Get the number for a given word\n",
    "print(word_index['favorite'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcN_yM8O1oSX"
   },
   "source": [
    "# Create sequences for the sentences\n",
    "\n",
    "After you tokenize the words, the word index contains a unique number for each word. However, the numbers in the word index are not ordered. Words in a sentence have an order. So after tokenizing the words, the next step is to generate sequences for the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QlUL6Ybf1sso",
    "outputId": "a9ecb828-8b0f-4bc8-d8ea-919bf8516658"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "print (sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AswZPbuW8f-f"
   },
   "source": [
    "# Sequence sentences that contain words that are not in the word index\n",
    "\n",
    "Let's take a look at what happens if the sentence being sequenced contains words that are not in the word index.\n",
    "\n",
    "The Out of Vocabluary (OOV) token is the first entry in the word index. You will see it shows up in the sequences in place of any word that is not in the word index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fir7qd6X8eZc",
    "outputId": "762668de-b6da-4eb9-99e3-6c23ee3a55dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 13, 1, 9], [5, 22, 24, 5, 1, 13, 1, 1, 5, 1, 1, 1, 24, 5, 1, 13, 3, 4, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "sentences2 = [\"I like hot chocolate\", \"My dogs and my hedgehog like kibble but my squirrel prefers grapes and my chickens like ice cream, preferably vanilla\"]\n",
    "\n",
    "sequences2 = tokenizer.texts_to_sequences(sentences2)\n",
    "print(sequences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZ1aIJo8NLb1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX9Yx50TUies"
   },
   "source": [
    "# Preparing text to use with TensorFlow models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5Uhzt6vVIB2"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l09c02_nlp_padding.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l09c02_nlp_padding.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_MCdtjT-bly"
   },
   "source": [
    "The high level steps to prepare text to be used in a machine learning model are:\n",
    "\n",
    "1.   Tokenize the words to get numerical values for them\n",
    "2.   Create numerical sequences of the sentences\n",
    "3.   Adjust the sequences to all be the same length.\n",
    "\n",
    "In this colab, you learn how to use padding to make the sequences all be the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJsd8KslUn7j"
   },
   "source": [
    "## Import the classes you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_ZxQf11OUtQI"
   },
   "outputs": [],
   "source": [
    "# Import Tokenizer and pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MeEgRq4WX0v"
   },
   "source": [
    "## Write some sentences\n",
    "\n",
    "Feel free to write your own sentences here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PwM7IP2lTr7T",
    "outputId": "c2f7136e-d3ea-4c53-f1f6-9d43941e8120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My favorite food is ice cream', 'do you like ice cream too?', 'My dog likes ice cream!', 'your favorite flavor of icecream is chocolate', \"chocolate isn't good for dogs\", 'your dog, your cat, and your parrot prefer broccoli']\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    'My favorite food is ice cream',\n",
    "    'do you like ice cream too?',\n",
    "    'My dog likes ice cream!',\n",
    "    \"your favorite flavor of icecream is chocolate\",\n",
    "    \"chocolate isn't good for dogs\",\n",
    "    \"your dog, your cat, and your parrot prefer broccoli\"\n",
    "]\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaRa9opNWmA7"
   },
   "source": [
    "## Create the Tokenizer and define an out of vocabulary token\n",
    "When creating the Tokenizer, you can specify the max number of words in the dictionary. You can also specify a token to represent words that are out of the vocabulary (OOV), in other words, that are not in the dictionary. This OOV token will be used when you create sequences for sentences that contain words that are not in the word index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "P7wuOJaBWiHZ"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7nILrhKXPge"
   },
   "source": [
    "## Tokenize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXooiuwrXROU",
    "outputId": "5767e20a-19a2-4f94-b481-8cc7cf2f9201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U-oe201Xm7T"
   },
   "source": [
    "## Turn sentences into sequences \n",
    "\n",
    "Each word now has a unique number in the word index.  However, words in a sentence are in a specific order. You can't just randomly mix up words and have the outcome be a sentence.\n",
    "\n",
    "For example, although \"chocolate isn't good for dogs\" is a perfectly fine sentence, \"dogs isn't for chocolate good\" does not make sense as a sentence.\n",
    "\n",
    "So the next step to representing text in a way that can be meaningfully used by machine learning programs is to create numerical sequences that represent the sentences in the text.\n",
    "\n",
    "Each sentence will be converted into a sequence where each word is replaced by its number in the word index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70l5x1XRXoV4",
    "outputId": "45b9a236-e4ed-414f-f4a9-47d13d70f951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "print (sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcFghvQ34cZK"
   },
   "source": [
    "## Make the sequences all the same length\n",
    "\n",
    "Later, when you feed the sequences into a neural network to train a model, the sequences all need to be uniform in size. Currently the sequences have varied lengths, so the next step is to make them all be the same size, either by padding them with zeros and/or truncating them.\n",
    "\n",
    "Use f.keras.preprocessing.sequence.pad_sequences to add zeros to the sequences to make them all be the same length. By default, the padding goes at the start of the sequences, but you can specify to pad at the end.\n",
    "\n",
    "You can optionally specify the maximum length to pad the sequences to. Sequences that are longer than the specified max length will be truncated. By default, sequences are truncated from the beginning of the sequence, but you can specify to truncate from the end.\n",
    "\n",
    "If you don't provide the max length, then the sequences are padded to match the length of the longest sentence.\n",
    "\n",
    "For all the options when padding and truncating sequences, see https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r0m_nqHg4gqu",
    "outputId": "2d9ef165-812d-484a-9116-5bcaf2003c39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Index =  {'<OOV>': 1, 'your': 2, 'ice': 3, 'cream': 4, 'my': 5, 'favorite': 6, 'is': 7, 'dog': 8, 'chocolate': 9, 'food': 10, 'do': 11, 'you': 12, 'like': 13, 'too': 14, 'likes': 15, 'flavor': 16, 'of': 17, 'icecream': 18, \"isn't\": 19, 'good': 20, 'for': 21, 'dogs': 22, 'cat': 23, 'and': 24, 'parrot': 25, 'prefer': 26, 'broccoli': 27}\n",
      "\n",
      "Sequences =  [[5, 6, 10, 7, 3, 4], [11, 12, 13, 3, 4, 14], [5, 8, 15, 3, 4], [2, 6, 16, 17, 18, 7, 9], [9, 19, 20, 21, 22], [2, 8, 2, 23, 24, 2, 25, 26, 27]]\n",
      "\n",
      "Padded Sequences:\n",
      "[[ 0  0  0  5  6 10  7  3  4]\n",
      " [ 0  0  0 11 12 13  3  4 14]\n",
      " [ 0  0  0  0  5  8 15  3  4]\n",
      " [ 0  0  2  6 16 17 18  7  9]\n",
      " [ 0  0  0  0  9 19 20 21 22]\n",
      " [ 2  8  2 23 24  2 25 26 27]]\n"
     ]
    }
   ],
   "source": [
    "padded = pad_sequences(sequences)\n",
    "print(\"\\nWord Index = \" , word_index)\n",
    "print(\"\\nSequences = \" , sequences)\n",
    "print(\"\\nPadded Sequences:\")\n",
    "print(padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VzbGtYWQ6Ofo",
    "outputId": "7bfae07f-4536-4f2b-93fa-5e9dc8e08aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  5  6 10  7  3  4]\n",
      " [ 0  0  0  0  0  0  0  0  0 11 12 13  3  4 14]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  5  8 15  3  4]\n",
      " [ 0  0  0  0  0  0  0  0  2  6 16 17 18  7  9]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9 19 20 21 22]\n",
      " [ 0  0  0  0  0  0  2  8  2 23 24  2 25 26 27]]\n"
     ]
    }
   ],
   "source": [
    "# Specify a max length for the padded sequences\n",
    "padded = pad_sequences(sequences, maxlen=15)\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HzkbHi0B64w8",
    "outputId": "55460c9c-ce5c-4dd8-efc4-7b640531e16f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  6 10  7  3  4  0  0  0  0  0  0  0  0  0]\n",
      " [11 12 13  3  4 14  0  0  0  0  0  0  0  0  0]\n",
      " [ 5  8 15  3  4  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  6 16 17 18  7  9  0  0  0  0  0  0  0  0]\n",
      " [ 9 19 20 21 22  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2  8  2 23 24  2 25 26 27  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Put the padding at the end of the sequences\n",
    "padded = pad_sequences(sequences, maxlen=15, padding=\"post\")\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLHheI477okX",
    "outputId": "8dde3cd7-e5e9-47e4-edef-f7a7df0005ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  3  4]\n",
      " [ 3  4 14]\n",
      " [15  3  4]\n",
      " [18  7  9]\n",
      " [20 21 22]\n",
      " [25 26 27]]\n"
     ]
    }
   ],
   "source": [
    "# Limit the length of the sequences, you will see some sequences get truncated\n",
    "padded = pad_sequences(sequences, maxlen=3)\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OnRKDsR197-J"
   },
   "source": [
    "## What happens if some of the sentences contain words that are not in the word index?\n",
    "\n",
    "Here's where the \"out of vocabulary\" token is used. Try generating sequences for some sentences that have words that are not in the word index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqodOpn64c2U",
    "outputId": "55d36bb0-9f7b-4add-d337-a6815e38e891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"my best friend's favorite ice cream flavor is strawberry\", \"my dog's best friend is a manatee\"]\n",
      "<OOV> has the number 1 in the word index.\n",
      "\n",
      "Test Sequence =  [[5, 1, 1, 6, 3, 4, 16, 7, 1], [5, 1, 1, 1, 7, 1, 1]]\n",
      "\n",
      "Padded Test Sequence: \n",
      "[[ 0  5  1  1  6  3  4 16  7  1]\n",
      " [ 0  0  0  5  1  1  1  7  1  1]]\n"
     ]
    }
   ],
   "source": [
    "# Try turning sentences that contain words that \n",
    "# aren't in the word index into sequences.\n",
    "# Add your own sentences to the test_data\n",
    "test_data = [\n",
    "    \"my best friend's favorite ice cream flavor is strawberry\",\n",
    "    \"my dog's best friend is a manatee\"\n",
    "]\n",
    "print (test_data)\n",
    "\n",
    "# Remind ourselves which number corresponds to the\n",
    "# out of vocabulary token in the word index\n",
    "print(\"<OOV> has the number\", word_index['<OOV>'], \"in the word index.\")\n",
    "\n",
    "# Convert the test sentences to sequences\n",
    "test_seq = tokenizer.texts_to_sequences(test_data)\n",
    "print(\"\\nTest Sequence = \", test_seq)\n",
    "\n",
    "# Pad the new sequences\n",
    "padded = pad_sequences(test_seq, maxlen=10)\n",
    "print(\"\\nPadded Test Sequence: \")\n",
    "\n",
    "# Notice that \"1\" appears in the sequence wherever there's a word \n",
    "# that's not in the word index\n",
    "print(padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTh4JzowOaOv"
   },
   "source": [
    "## tokenization w/ big data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PyxaJCfoOdeZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wr21SvWhQhvN"
   },
   "outputs": [],
   "source": [
    "# Import Tokenizer and pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJOCSbdERsdc"
   },
   "source": [
    "# Get the corpus of text\n",
    "\n",
    "The combined dataset of reviews has been saved in a Google drive belonging to Udacity. You can download it from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBpFip-X69Hf",
    "outputId": "431ea71d-3a7e-405e-8ef7-f8e804cfee34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\n",
      "127831/127831 [==============================] - 0s 0us/step\n",
      "/root/.keras/datasets/reviews.csv\n"
     ]
    }
   ],
   "source": [
    "path = tf.keras.utils.get_file('reviews.csv', \n",
    "                               'https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P')\n",
    "print (path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCT57MVGTENX"
   },
   "source": [
    "# Get the dataset\n",
    "\n",
    "Each row in the csv file is a separate review.\n",
    "\n",
    "The csv file has 2 columns:\n",
    "\n",
    "*   **text** (the review)\n",
    "*   **sentiment** (0 or 1 indicating a bad or good review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TlyreClyS7H3",
    "outputId": "4a15f2e7-1733-4881-9d11-356badf5dd1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3b56d8b5-03e9-4b28-abda-5d61f0e05ecf\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b56d8b5-03e9-4b28-abda-5d61f0e05ecf')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3b56d8b5-03e9-4b28-abda-5d61f0e05ecf button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3b56d8b5-03e9-4b28-abda-5d61f0e05ecf');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  sentiment\n",
       "0           0  So there is no way for me to plug it in here i...          0\n",
       "1           1                         Good case Excellent value.          1\n",
       "2           2                             Great for the jawbone.          1\n",
       "3           3  Tied to charger for conversations lasting more...          0\n",
       "4           4                                  The mic is great.          1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file\n",
    "dataset = pd.read_csv(path)\n",
    "\n",
    "# Review the first few entries in the dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fk5uzq4Oco7h"
   },
   "source": [
    "# Get the reviews from the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "u7uCBlAqdEzK"
   },
   "outputs": [],
   "source": [
    "# Get the reviews from the text column\n",
    "reviews = dataset['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS0mg5yoVzQL"
   },
   "source": [
    "# Tokenize the text\n",
    "Create the tokenizer, specify the OOV token, tokenize the text, then inspect the word index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atgLJzAiVwqB",
    "outputId": "056080f0-2801-4864-ec07-6c518f7e1036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3261\n",
      "{'<OOV>': 1, 'the': 2, 'and': 3, 'i': 4, 'a': 5, 'it': 6, 'to': 7, 'is': 8, 'was': 9, 'this': 10, 'of': 11, 'not': 12, 'for': 13, 'my': 14, 'in': 15, 'with': 16, 'very': 17, 'good': 18, 'great': 19, 'phone': 20, 'that': 21, 'on': 22, 'have': 23, 'you': 24, 'food': 25, 'had': 26, 'place': 27, 'so': 28, 'but': 29, 'service': 30, 'are': 31, 'be': 32, 'we': 33, 'all': 34, 'as': 35, 'at': 36, 'like': 37, 'they': 38, 'time': 39, 'back': 40, 'one': 41, 'were': 42, 'quality': 43, 'would': 44, 'really': 45, 'here': 46, 'if': 47, 'from': 48, 'well': 49, 'your': 50, 'just': 51, 'product': 52, 'up': 53, 'best': 54, \"don't\": 55, 'no': 56, 'will': 57, 'an': 58, 'there': 59, 'go': 60, 'me': 61, 'has': 62, 'only': 63, 'also': 64, 'works': 65, \"i've\": 66, 'out': 67, 'headset': 68, 'nice': 69, 'ever': 70, 'battery': 71, \"it's\": 72, 'sound': 73, 'than': 74, 'use': 75, 'or': 76, 'when': 77, \"i'm\": 78, 'our': 79, 'get': 80, 'what': 81, 'their': 82, 'after': 83, 'love': 84, 'been': 85, 'did': 86, 'excellent': 87, 'recommend': 88, 'even': 89, 'more': 90, 'again': 91, 'first': 92, 'too': 93, 'work': 94, 'which': 95, 'ear': 96, 'about': 97, '2': 98, 'better': 99, 'can': 100, 'never': 101, 'price': 102, 'any': 103, 'could': 104, 'bad': 105, 'because': 106, 'do': 107, 'made': 108, 'got': 109, 'case': 110, 'pretty': 111, 'much': 112, 'by': 113, 'now': 114, 'disappointed': 115, 'worst': 116, 'friendly': 117, 'does': 118, 'them': 119, 'some': 120, 'then': 121, 'think': 122, 'am': 123, 'came': 124, 'minutes': 125, 'money': 126, 'new': 127, 'enough': 128, 'still': 129, 'these': 130, 'other': 131, 'amazing': 132, 'restaurant': 133, 'going': 134, 'how': 135, 'definitely': 136, 'say': 137, 'happy': 138, 'off': 139, 'experience': 140, 'delicious': 141, 'way': 142, 'two': 143, 'few': 144, 'while': 145, 'over': 146, 'being': 147, 'vegas': 148, 'us': 149, 'right': 150, 'poor': 151, 'thing': 152, 'everything': 153, \"won't\": 154, 'he': 155, 'far': 156, 'went': 157, \"didn't\": 158, 'car': 159, 'make': 160, '1': 161, 'item': 162, 'worked': 163, 'terrible': 164, 'always': 165, 'charger': 166, 'waste': 167, 'comfortable': 168, 'people': 169, 'want': 170, 'buy': 171, 'used': 172, 'staff': 173, 'eat': 174, 'long': 175, 'bought': 176, 'little': 177, 'bluetooth': 178, 'down': 179, 'easy': 180, 'its': 181, 'impressed': 182, '5': 183, 'reception': 184, 'piece': 185, 'awesome': 186, 'ordered': 187, 'stars': 188, 'times': 189, \"doesn't\": 190, 'fine': 191, 'lot': 192, 'know': 193, \"wasn't\": 194, 'chicken': 195, 'charge': 196, 'life': 197, 'since': 198, 'order': 199, 'found': 200, 'tried': 201, 'both': 202, 'fantastic': 203, 'same': 204, 'every': 205, 'before': 206, 'customer': 207, 'quite': 208, 'take': 209, 'another': 210, 'menu': 211, 'salad': 212, 'pizza': 213, 'last': 214, 'problem': 215, 'purchase': 216, 'cell': 217, 'around': 218, 'small': 219, 'slow': 220, 'horrible': 221, 'worth': 222, 'many': 223, 'feel': 224, \"can't\": 225, 'fresh': 226, 'wait': 227, 'steak': 228, 'highly': 229, 'she': 230, 'talk': 231, 'sure': 232, '3': 233, 'camera': 234, 'calls': 235, 'device': 236, \"couldn't\": 237, 'night': 238, 'overall': 239, 'probably': 240, 'day': 241, 'come': 242, 'next': 243, 'taste': 244, 'server': 245, 'sushi': 246, 'flavor': 247, 'problems': 248, 'volume': 249, 'into': 250, 'absolutely': 251, 'hear': 252, 'years': 253, 'clear': 254, 'real': 255, 'cool': 256, 'working': 257, 'using': 258, 'motorola': 259, 'fit': 260, 'look': 261, 'try': 262, 'give': 263, 'bland': 264, 'nothing': 265, 'said': 266, 'coming': 267, 'burger': 268, 'plug': 269, 'must': 270, 'design': 271, 'who': 272, 'makes': 273, 'loved': 274, 'looks': 275, 'call': 276, 'fits': 277, 'getting': 278, 'cheap': 279, 'side': 280, 'where': 281, 'family': 282, 'low': 283, 'however': 284, 'deal': 285, 'hard': 286, 'perfect': 287, 'tasty': 288, 'buffet': 289, 'meal': 290, 'atmosphere': 291, 'several': 292, 'without': 293, 'months': 294, 'left': 295, 'phones': 296, 'should': 297, 'seriously': 298, 'big': 299, 'super': 300, 'expect': 301, 'area': 302, 'screen': 303, 'once': 304, 'felt': 305, \"i'd\": 306, 'bit': 307, 'year': 308, 'return': 309, 'either': 310, 'old': 311, 'disappointing': 312, 'hot': 313, 'took': 314, 'soon': 315, 'selection': 316, 'prices': 317, 'sauce': 318, 'lunch': 319, 'breakfast': 320, 'waited': 321, 'days': 322, 'helpful': 323, 'need': 324, 'kept': 325, 'priced': 326, 'find': 327, 'wear': 328, 'received': 329, 'high': 330, 'light': 331, 'fast': 332, 'completely': 333, 'job': 334, 'kind': 335, 'perfectly': 336, 'stay': 337, '10': 338, 'company': 339, 'disappointment': 340, 'hands': 341, 'amazon': 342, 'looking': 343, \"i'll\": 344, 'away': 345, 'bar': 346, 'inside': 347, 'fries': 348, 'table': 349, 'sandwich': 350, 'meat': 351, 'dishes': 352, 'clean': 353, 'cold': 354, 'most': 355, 'three': 356, 'simple': 357, 'verizon': 358, 'dropped': 359, 'end': 360, 'buttons': 361, 'different': 362, 'gets': 363, 'home': 364, 'arrived': 365, 'quickly': 366, 'broke': 367, 'black': 368, 'may': 369, 'jabra': 370, 'pleased': 371, 'done': 372, 'avoid': 373, 'voice': 374, 'check': 375, 'extremely': 376, 'thought': 377, 'tell': 378, 'junk': 379, 'couple': 380, 'especially': 381, 'unit': 382, 'anyone': 383, 'unfortunately': 384, 'wrong': 385, 'none': 386, 'hour': 387, 'waitress': 388, 'beer': 389, 'dish': 390, 'eating': 391, 'dining': 392, 'spicy': 393, 'spot': 394, 'rude': 395, 'tasted': 396, 'value': 397, 'each': 398, 'started': 399, 'though': 400, 'everyone': 401, 'picture': 402, 'audio': 403, 'loud': 404, 'week': 405, 'feels': 406, 'headsets': 407, 'huge': 408, 'full': 409, 'software': 410, 'during': 411, 'hours': 412, 'internet': 413, 'less': 414, 'put': 415, 'useless': 416, 'color': 417, 'part': 418, 'expected': 419, 'authentic': 420, 'nokia': 421, 'anything': 422, 'sucks': 423, 'ago': 424, 'wanted': 425, 'waiting': 426, 'rather': 427, 'those': 428, 'things': 429, 'cannot': 430, 'enjoy': 431, 'barely': 432, 'quick': 433, 'pay': 434, 'awful': 435, 'mediocre': 436, 'management': 437, 'see': 438, 'overpriced': 439, 'warm': 440, 'waiter': 441, 'attentive': 442, 'cooked': 443, 'wonderful': 444, 'town': 445, 'ambiance': 446, 'chips': 447, 'special': 448, 'unless': 449, 'decent': 450, 'original': 451, 'yet': 452, 'bars': 453, 'ears': 454, 'hate': 455, 'least': 456, 'turn': 457, 'seems': 458, 'actually': 459, 'large': 460, 'reasonable': 461, 'headphones': 462, 'later': 463, 'beautiful': 464, 'within': 465, 'free': 466, 'pictures': 467, 'such': 468, 'wife': 469, 'ask': 470, 'signal': 471, 'set': 472, 'house': 473, 'glad': 474, 'incredible': 475, 'hit': 476, 'thin': 477, 'mistake': 478, 'cable': 479, 'care': 480, 'lacking': 481, 'having': 482, 'outside': 483, 'others': 484, 'crap': 485, 'plastic': 486, 'oh': 487, 'difficult': 488, '20': 489, 'under': 490, 'star': 491, 'zero': 492, 'samsung': 493, 'extra': 494, 'something': 495, '4': 496, 'easily': 497, 'places': 498, 'pho': 499, 'shrimp': 500, 'tender': 501, 'his': 502, 'potato': 503, 'served': 504, 'her': 505, 'twice': 506, 'dinner': 507, 'line': 508, 'fun': 509, 'razr': 510, 'blue': 511, 'charging': 512, 'mobile': 513, 'hold': 514, 'sturdy': 515, 'party': 516, 'front': 517, 'longer': 518, 'bargain': 519, 'music': 520, 'dont': 521, 'shipping': 522, 'between': 523, 'white': 524, 'although': 525, 'leather': 526, 'strong': 527, 'weeks': 528, 'almost': 529, 'literally': 530, \"wouldn't\": 531, 'charm': 532, 'obviously': 533, 'options': 534, 'needs': 535, 'lost': 536, 'simply': 537, 'reasonably': 538, 'range': 539, 'room': 540, 'important': 541, 'gave': 542, 'feature': 543, 'buying': 544, 'someone': 545, 'weak': 546, 'belt': 547, 'data': 548, 'sides': 549, 'average': 550, 'trying': 551, 'finally': 552, 'today': 553, 'satisfied': 554, 'keep': 555, 'clarity': 556, 'given': 557, 'review': 558, 'store': 559, 'replace': 560, 'above': 561, 'sucked': 562, 't': 563, 'friends': 564, 'please': 565, 'needed': 566, 'plus': 567, 'cases': 568, 'connection': 569, 'reviews': 570, 'told': 571, 'beat': 572, 'wall': 573, 'elsewhere': 574, 'break': 575, 'rare': 576, 'thumbs': 577, 'dirty': 578, 'ok': 579, 'fact': 580, 'wow': 581, 'asked': 582, 'tables': 583, 'portions': 584, 'sick': 585, 'dessert': 586, 'beef': 587, 'servers': 588, 'seafood': 589, 'pasta': 590, 'tasteless': 591, 'fish': 592, '30': 593, 'sweet': 594, 'thai': 595, 'eaten': 596, 'seated': 597, 'bacon': 598, 'sat': 599, 'ice': 600, 'bread': 601, 'fried': 602, 'enjoyed': 603, 'anytime': 604, 'bring': 605, 'mic': 606, 'sending': 607, 'owner': 608, 'clip': 609, 'below': 610, '7': 611, 'instructions': 612, 'provided': 613, 'included': 614, 'recommended': 615, 'performance': 616, 'thats': 617, 'keyboard': 618, 'instead': 619, 'support': 620, 'perhaps': 621, 'player': 622, 'let': 623, 'person': 624, 'station': 625, 'purchased': 626, 'holds': 627, 'decision': 628, 'comfortably': 629, 'basically': 630, 'stuff': 631, 'forever': 632, 'goes': 633, 'tool': 634, 'lasts': 635, 'bother': 636, 'able': 637, 'lightweight': 638, 'favorite': 639, 'market': 640, 'earpiece': 641, '8': 642, 'unreliable': 643, 'whole': 644, 'seller': 645, 'plantronics': 646, 'poorly': 647, 'charged': 648, 'strip': 649, 'lg': 650, 'immediately': 651, 'cant': 652, 'easier': 653, 'face': 654, 'happier': 655, 'comes': 656, 'dead': 657, 'might': 658, 'expensive': 659, 'liked': 660, 'palm': 661, 'ended': 662, 'touch': 663, 'own': 664, 'total': 665, 'cingular': 666, \"isn't\": 667, 'ringtones': 668, 'joke': 669, 'stop': 670, 'walked': 671, 'course': 672, 'treo': 673, 'usb': 674, 'believe': 675, 'point': 676, 'red': 677, 'guess': 678, 'third': 679, 'chinese': 680, 'despite': 681, 'hand': 682, 'cut': 683, 'else': 684, 'until': 685, 'checked': 686, 'setting': 687, 'totally': 688, 'damn': 689, 'tacos': 690, 'running': 691, 'salmon': 692, 'visit': 693, 'establishment': 694, 'husband': 695, 'heart': 696, 'drinks': 697, 'rice': 698, 'yummy': 699, \"we'll\": 700, 'wine': 701, 'trip': 702, 'steaks': 703, 'leave': 704, 'pork': 705, 'burgers': 706, 'cream': 707, 'drink': 708, 'itself': 709, 'considering': 710, 'bay': 711, 'phoenix': 712, 'sad': 713, 'wings': 714, 'live': 715, 'drive': 716, 'business': 717, 'folks': 718, '0': 719, 'chef': 720, 'possible': 721, 'close': 722, 'tea': 723, 'why': 724, 'location': 725, 'vegetables': 726, 'soup': 727, 'owners': 728, '40': 729, 'manager': 730, 'dry': 731, 'jawbone': 732, 'conversations': 733, 'contacts': 734, 'needless': 735, 'wasted': 736, 'static': 737, 'website': 738, 'pair': 739, \"that's\": 740, 'pocket': 741, 'pc': 742, 'combination': 743, 'owned': 744, 'book': 745, 'worthless': 746, 'features': 747, 'mind': 748, 'returned': 749, 'protection': 750, 'world': 751, 'seconds': 752, '510': 753, 'complaints': 754, 'particular': 755, \"phone's\": 756, 'cover': 757, 'fairly': 758, 'trouble': 759, 'saying': 760, 'choice': 761, 'packaged': 762, '6': 763, 'loves': 764, 'construction': 765, 'boy': 766, 'ease': 767, 'play': 768, 'plan': 769, 'match': 770, 'pros': 771, 'rated': 772, 'impressive': 773, 'fall': 774, 'display': 775, 'rocks': 776, 'number': 777, 'setup': 778, 'earpieces': 779, 'bt': 780, 'earbud': 781, 'failed': 782, 'coverage': 783, 'experienced': 784, 'drops': 785, 'description': 786, 'hoping': 787, 'seemed': 788, 'sharp': 789, 'wasting': 790, 'chargers': 791, 'offers': 792, 'handsfree': 793, 'network': 794, 'recently': 795, 'bucks': 796, 'replacement': 797, 'nearly': 798, 'form': 799, 'anyway': 800, 'means': 801, \"there's\": 802, 'certainly': 803, 'mess': 804, 'hair': 805, 'sony': 806, 'comfort': 807, 'cute': 808, 'whatsoever': 809, 'drain': 810, 'fry': 811, 'scratched': 812, 'microphone': 813, 'uncomfortable': 814, 'plugged': 815, 'gotten': 816, 'driving': 817, 'neither': 818, 'flip': 819, 'inexpensive': 820, 'sitting': 821, 'wireless': 822, 'reason': 823, 'exactly': 824, \"you'd\": 825, 'stupid': 826, 'breaks': 827, 'note': 828, 'alone': 829, 'q': 830, 'size': 831, 'turned': 832, 'reading': 833, 'wearing': 834, 'sunglasses': 835, 'computer': 836, 'returning': 837, 'understand': 838, 'pricing': 839, 'results': 840, 'im': 841, 'noise': 842, 'holster': 843, 'orders': 844, 'refund': 845, 'drop': 846, 'through': 847, 'speaker': 848, 'sprint': 849, 'stopped': 850, 'tinny': 851, 'placed': 852, 'spring': 853, 'happened': 854, 'pairing': 855, 'crisp': 856, 'ripped': 857, 'iphone': 858, 'multiple': 859, 'power': 860, 'outlet': 861, 'etc': 862, 'passed': 863, '100': 864, 'convenient': 865, 'date': 866, 'bottom': 867, '12': 868, 'boot': 869, 'double': 870, 'disgusting': 871, 'lots': 872, 'together': 873, 'send': 874, 'says': 875, 'top': 876, 'making': 877, 'fails': 878, 'beep': 879, 'word': 880, 'complain': 881, 'seen': 882, 'disappoint': 883, 'texture': 884, 'nasty': 885, 'recommendation': 886, 'potatoes': 887, 'brought': 888, 'sashimi': 889, 'yourself': 890, 'moist': 891, 'frozen': 892, 'greek': 893, 'dressing': 894, 'pita': 895, 'hummus': 896, 'duck': 897, 'flat': 898, 'amount': 899, 'water': 900, 'second': 901, 'salt': 902, 'chewy': 903, 'rolls': 904, 'mouth': 905, \"you're\": 906, 'tip': 907, 'cafe': 908, 'ambience': 909, 'honest': 910, 'busy': 911, 'delish': 912, 'melt': 913, 'cheese': 914, 'subway': 915, 'restaurants': 916, 'empty': 917, 'ate': 918, 'watched': 919, 'stale': 920, 'treated': 921, 'vegetarian': 922, 'healthy': 923, 'interesting': 924, 'decor': 925, 'butter': 926, 'egg': 927, 'dog': 928, 'insulted': 929, 'hope': 930, 'brunch': 931, 'soggy': 932, 'lobster': 933, 'flavorful': 934, 'par': 935, 'generous': 936, 'patio': 937, 'outstanding': 938, \"friend's\": 939, 'pizzas': 940, 'pulled': 941, 'pleasant': 942, 'equally': 943, 'bathroom': 944, 'door': 945, 'deserves': 946, 'stomach': 947, 'green': 948, 'beans': 949, 'regular': 950, '35': 951, 'bill': 952, 'worse': 953, 'meals': 954, 'homemade': 955, 'gone': 956, 'desserts': 957, 'boyfriend': 958, 'maybe': 959, 'half': 960, 'list': 961, 'vibe': 962, 'him': 963, 'edible': 964, 'seating': 965, 'style': 966, 'salsa': 967, 'lacked': 968, 'lasting': 969, '45': 970, 'imagine': 971, 'extended': 972, 'notice': 973, 'tooth': 974, 'advise': 975, 'fire': 976, 'run': 977, 'pull': 978, 'unusable': 979, 'juice': 980, 'short': 981, 'regarding': 982, 'turns': 983, 'pda': 984, 'neat': 985, '15': 986, 'essentially': 987, 'forget': 988, 'tech': 989, 'clearly': 990, 'mp3': 991, 'songs': 992, 'lock': 993, 'died': 994, 'glasses': 995, 'sometimes': 996, 'series': 997, 'quiet': 998, 'docking': 999, 'd807': 1000, 'advertised': 1001, 'handy': 1002, 'cheaper': 1003, 'costs': 1004, 'buyer': 1005, 'beware': 1006, 'apparently': 1007, 'flaw': 1008, 'expectations': 1009, 'resolution': 1010, 'slim': 1011, 'sex': 1012, 'toast': 1013, 'sleek': 1014, 'keypad': 1015, 'unhappy': 1016, 'winner': 1017, 'careful': 1018, 'logitech': 1019, 'recognition': 1020, 'tremendous': 1021, 'takes': 1022, 'stated': 1023, 'blackberry': 1024, 'sounds': 1025, 'funny': 1026, 'technology': 1027, 'wired': 1028, 'previous': 1029, 's': 1030, 'w810i': 1031, 'superb': 1032, 'maintain': 1033, \"shouldn't\": 1034, 'graphics': 1035, 'button': 1036, 'thank': 1037, 'igo': 1038, 'tips': 1039, 'connected': 1040, \"wife's\": 1041, 'whether': 1042, 'likes': 1043, 'storage': 1044, 'buzzing': 1045, 'override': 1046, 'functionality': 1047, 'ring': 1048, 'dropping': 1049, 'hardly': 1050, \"you'll\": 1051, 'incredibly': 1052, 'strange': 1053, 'living': 1054, 'issues': 1055, 'embarrassing': 1056, 'mostly': 1057, 'consumer': 1058, 'background': 1059, 'usually': 1060, 'excited': 1061, 'additional': 1062, 'gels': 1063, 'purpose': 1064, 'secure': 1065, 'appears': 1066, 'rubber': 1067, 'smell': 1068, 'caused': 1069, 'flimsy': 1070, 'month': 1071, 'flawlessly': 1072, 'giving': 1073, 'rotating': 1074, 'adorable': 1075, 'thru': 1076, 'wise': 1077, 'compliments': 1078, 'dialing': 1079, 'games': 1080, 'ipod': 1081, 'recharge': 1082, 'appealing': 1083, 'save': 1084, 'along': 1085, 'starts': 1086, 'ringing': 1087, 'auto': 1088, 'push': 1089, 'skype': 1090, 'self': 1091, 'help': 1092, 'shipped': 1093, 'promptly': 1094, 'prompt': 1095, 'noticed': 1096, 'att': 1097, 'mention': 1098, 'weird': 1099, 'effect': 1100, 'model': 1101, 'warning': 1102, 'wish': 1103, 'dying': 1104, 'install': 1105, 'purchasing': 1106, 'moto': 1107, 'figure': 1108, 'key': 1109, 'memory': 1110, 'solid': 1111, 'changing': 1112, 'update': 1113, 'cumbersome': 1114, 'delivery': 1115, 'switch': 1116, 'worthwhile': 1117, 'batteries': 1118, 'user': 1119, 'ability': 1120, 'receiving': 1121, 'exchanged': 1122, 'cellphone': 1123, 'described': 1124, '11': 1125, 'nyc': 1126, 'defective': 1127, 'unacceptable': 1128, 'catching': 1129, 'amazed': 1130, 'timeframe': 1131, 'complaint': 1132, 'standard': 1133, 'thanks': 1134, 'accidentally': 1135, 'listening': 1136, 'kitchen': 1137, 'conversation': 1138, 'ample': 1139, 'eargels': 1140, 'seem': 1141, 'ones': 1142, 'properly': 1143, 'missed': 1144, 'numerous': 1145, 'hated': 1146, 'due': 1147, 'forced': 1148, 'constructed': 1149, 'menus': 1150, 'holding': 1151, 'broken': 1152, 'effort': 1153, 'idea': 1154, \"they're\": 1155, 'doing': 1156, 'killer': 1157, 'breaking': 1158, '50': 1159, 'operate': 1160, 'paired': 1161, 'pack': 1162, 'apart': 1163, 'brand': 1164, 'surprised': 1165, 'fabulous': 1166, 'performed': 1167, 'echo': 1168, 'wind': 1169, 'warranty': 1170, 'luck': 1171, 'falling': 1172, 'tiny': 1173, 'four': 1174, 'tries': 1175, 'download': 1176, 'rate': 1177, 'access': 1178, 'continue': 1179, 'somehow': 1180, 'flash': 1181, 'truly': 1182, 'tones': 1183, 'prime': 1184, 'biggest': 1185, 'video': 1186, 'entire': 1187, 'accept': 1188, 'shots': 1189, 'allows': 1190, 'quit': 1191, 'via': 1192, 'signs': 1193, 'sizes': 1194, 'provides': 1195, 'classy': 1196, 'metro': 1197, 'somewhat': 1198, 'cost': 1199, 'smoke': 1200, 'son': 1201, 'protector': 1202, 'sorry': 1203, 'refused': 1204, 'discount': 1205, 'five': 1206, 'sounded': 1207, 'talking': 1208, 'feet': 1209, 'everywhere': 1210, 'ordering': 1211, 'awkward': 1212, 'current': 1213, 'answer': 1214, 'read': 1215, \"haven't\": 1216, 'letting': 1217, 'laptop': 1218, 'normal': 1219, 'lose': 1220, 'exceptional': 1221, 'show': 1222, 'managed': 1223, 'seat': 1224, 'lightly': 1225, 'rating': 1226, 'christmas': 1227, 'rest': 1228, 'otherwise': 1229, 'joy': 1230, 'covered': 1231, 'crust': 1232, 'late': 1233, 'cashier': 1234, 'mmmm': 1235, 'human': 1236, 'mexican': 1237, 'overwhelmed': 1238, 'bite': 1239, 'familiar': 1240, 'favor': 1241, 'delight': 1242, 'judge': 1243, 'grossed': 1244, 'behind': 1245, 'char': 1246, 'realized': 1247, 'attitudes': 1248, 'towards': 1249, 'customers': 1250, 'portion': 1251, 'attack': 1252, 'grill': 1253, 'downtown': 1254, 'excuse': 1255, 'scallop': 1256, 'refill': 1257, 'appetizers': 1258, 'heard': 1259, 'batter': 1260, 'finish': 1261, 'beyond': 1262, 'meh': 1263, 'min': 1264, 'known': 1265, 'suck': 1266, 'seasoned': 1267, 'opportunity': 1268, 'underwhelming': 1269, 'grease': 1270, 'roast': 1271, 'sugary': 1272, 'six': 1273, 'die': 1274, 'bye': 1275, 'lady': 1276, 'serves': 1277, 'roasted': 1278, 'garlic': 1279, 'marrow': 1280, 'added': 1281, 'bartender': 1282, 'playing': 1283, 'lovers': 1284, 'gross': 1285, 'preparing': 1286, 'indian': 1287, 'belly': 1288, 'crispy': 1289, 'wrap': 1290, 'tuna': 1291, 'bagels': 1292, 'selections': 1293, 'dine': 1294, 'rarely': 1295, 'curry': 1296, 'bathrooms': 1297, 'decorated': 1298, 'pace': 1299, 'greeted': 1300, 'joint': 1301, 'bakery': 1302, 'ladies': 1303, 'hip': 1304, 'overcooked': 1305, 'charcoal': 1306, 'decided': 1307, 'looked': 1308, 'dirt': 1309, 'watch': 1310, 'gyros': 1311, 'feeling': 1312, 'valley': 1313, 'bowl': 1314, 'disrespected': 1315, 'stepped': 1316, 'gold': 1317, 'puree': 1318, 'bug': 1319, \"we're\": 1320, 'friend': 1321, 'shower': 1322, 'bisque': 1323, 'filet': 1324, 'pepper': 1325, 'cook': 1326, 'dealing': 1327, 'cheeseburger': 1328, 'single': 1329, 'yum': 1330, 'mayo': 1331, 'honestly': 1332, 'stayed': 1333, 'building': 1334, 'dark': 1335, 'sub': 1336, 'creamy': 1337, 'similar': 1338, 'sticks': 1339, 'tap': 1340, 'coffee': 1341, 'boba': 1342, 'taco': 1343, 'bachi': 1344, 'salads': 1345, 'neighborhood': 1346, 'soooo': 1347, 'stir': 1348, 'summer': 1349, 'delightful': 1350, 'toasted': 1351, 'fare': 1352, 'doubt': 1353, 'serve': 1354, 'mom': 1355, 'bites': 1356, 'omg': 1357, 'brick': 1358, 'oven': 1359, 'ten': 1360, 'pancakes': 1361, 'eggs': 1362, 'treat': 1363, 'evening': 1364, 'lukewarm': 1365, 'eggplant': 1366, 'stuffed': 1367, 'mall': 1368, 'kids': 1369, 'perfection': 1370, 'impeccable': 1371, 'pop': 1372, 'assure': 1373, 'become': 1374, 'professional': 1375, \"we've\": 1376, 'nicest': 1377, 'biscuits': 1378, 'cow': 1379, 'driest': 1380, 'tots': 1381, 'paid': 1382, 'acknowledged': 1383, 'margaritas': 1384, 'flower': 1385, 'group': 1386, 'crab': 1387, 'legs': 1388, 'sliced': 1389, 'bunch': 1390, 'filling': 1391, 'lovely': 1392, 'choose': 1393, 'entrees': 1394, 'recent': 1395, 'tapas': 1396, 'vinegrette': 1397, 'baby': 1398, 'helped': 1399, 'fan': 1400, 'presentation': 1401, 'satisfying': 1402, 'grilled': 1403, 'non': 1404, 'focused': 1405, 'guy': 1406, 'promise': 1407, 'italian': 1408, 'legit': 1409, 'staying': 1410, 'fail': 1411, 'plate': 1412, 'serving': 1413, 'fly': 1414, 'paper': 1415, 'crowd': 1416, 'mid': 1417, 'definately': 1418, 'flavorless': 1419, 'nachos': 1420, 'crazy': 1421, 'tribute': 1422, 'fell': 1423, 'services': 1424, 'heat': 1425, \"aren't\": 1426, 'spend': 1427, 'undercooked': 1428, 'converter': 1429, 'tied': 1430, 'major': 1431, 'jiggle': 1432, 'dozen': 1433, 'hundred': 1434, 'seperated': 1435, 'mere': 1436, 'ft': 1437, 'excessive': 1438, 'garbled': 1439, 'odd': 1440, 'fooled': 1441, 'clicks': 1442, 'wonder': 1443, 'mechanism': 1444, \"motorola's\": 1445, 'followed': 1446, 'directions': 1447, 'kindle': 1448, 'commercials': 1449, 'misleading': 1450, 'mother': 1451, 'couldnt': 1452, 'earphone': 1453, 'breakage': 1454, 'unacceptible': 1455, 'ideal': 1456, 'whose': 1457, 'sensitive': 1458, 'moving': 1459, 'freeway': 1460, 'speed': 1461, 'contract': 1462, 'ac': 1463, 'highy': 1464, 'mins': 1465, '680': 1466, '2mp': 1467, 'pics': 1468, 'garbage': 1469, 'gonna': 1470, 'arguing': 1471, 'bulky': 1472, 'usable': 1473, 'useful': 1474, 'machine': 1475, 'gadget': 1476, 'e': 1477, 'stream': 1478, 'submerged': 1479, \"microsoft's\": 1480, 'faceplates': 1481, 'elegant': 1482, 'angle': 1483, 'drawback': 1484, 'pause': 1485, 'skip': 1486, 'activated': 1487, 'suddenly': 1488, 'ipods': 1489, 'situations': 1490, 'bmw': 1491, 'hearing': 1492, 'wrongly': 1493, 'everyday': 1494, 'intended': 1495, 'runs': 1496, 'loads': 1497, 'greater': 1498, 'buds': 1499, 'waaay': 1500, 'bluetooths': 1501, 'listener': 1502, 'integrated': 1503, 'seamlessly': 1504, 'flush': 1505, 'toilet': 1506, 'supposedly': 1507, '375': 1508, 'styles': 1509, 'correctly': 1510, '350': 1511, 'jabra350': 1512, 'megapixels': 1513, 'renders': 1514, 'images': 1515, 'relatively': 1516, 'purcashed': 1517, 'geeky': 1518, 'oozes': 1519, 'embedded': 1520, 'stylish': 1521, 'compromise': 1522, 'qwerty': 1523, 'basic': 1524, 'simpler': 1525, 'iam': 1526, 'disapoinment': 1527, 'realize': 1528, 'accompanied': 1529, 'brilliant': 1530, 'nicely': 1531, 'damage': 1532, 'definitly': 1533, 'majority': 1534, 'peachy': 1535, 'keen': 1536, 'upstairs': 1537, 'basement': 1538, 'minute': 1539, 'reccomendation': 1540, 'relative': 1541, 'items': 1542, 'sudden': 1543, 'linking': 1544, '8530': 1545, 'curve': 1546, 'sketchy': 1547, 'messages': 1548, 'web': 1549, 'browsing': 1550, 'significantly': 1551, 'faster': 1552, 'build': 1553, 'unlike': 1554, 'colors': 1555, 'whine': 1556, 'communications': 1557, 'communicate': 1558, 'monkeys': 1559, 'share': 1560, 'dna': 1561, 'copy': 1562, 'humans': 1563, 'bougth': 1564, 'l7c': 1565, 'mode': 1566, 'file': 1567, 'browser': 1568, 'hs850': 1569, 'latest': 1570, 'os': 1571, 'v1': 1572, '15g': 1573, 'crawl': 1574, 'recognizes': 1575, 'bluetoooth': 1576, 'thorn': 1577, 'abhor': 1578, 'disconnected': 1579, '13': 1580, 'mail': 1581, 'backlight': 1582, 'message': 1583, 'tone': 1584, 'lately': 1585, 'wit': 1586, 'weight': 1587, 'pleather': 1588, 'deaf': 1589, 'prettier': 1590, 'investment': 1591, 'ticking': 1592, 'noises': 1593, 'ends': 1594, 'electronics': 1595, 'available': 1596, 'fm': 1597, 'transmitters': 1598, 'h500': 1599, 'mega': 1600, 'pixel': 1601, 'good7': 1602, 'transmit': 1603, 'contacting': 1604, 'dollar': 1605, 'learned': 1606, 'lesson': 1607, 'online': 1608, 'earbugs': 1609, 'roam': 1610, 'crack': 1611, 'infatuated': 1612, 'freezes': 1613, 'frequently4': 1614, 'child': 1615, 'tick': 1616, 'headbands': 1617, 'ericsson': 1618, 'purchases': 1619, 'shine': 1620, 'calendar': 1621, 'sync': 1622, 'defeats': 1623, 'penny': 1624, 'wallet': 1625, 'type': 1626, 'excrutiatingly': 1627, 'aspect': 1628, 'glove': 1629, 'durable': 1630, 'o': 1631, 'gosh': 1632, 'attractive': 1633, 'factor': 1634, 'petroleum': 1635, 'unbearable': 1636, 'scary': 1637, 'stereo': 1638, 'absolutel': 1639, 'potentially': 1640, 'reversible': 1641, 'contstruct': 1642, 'hinge': 1643, 'installed': 1644, 'overnite': 1645, 'handset': 1646, 'cat': 1647, 'attacked': 1648, 'protective': 1649, 'destroying': 1650, 'razor': 1651, 'v3i': 1652, 'shouldve': 1653, 'invented': 1654, 'sooner': 1655, 'engineered': 1656, 'clever': 1657, 'complained': 1658, \"headset's\": 1659, '2160': 1660, 'tracfone': 1661, 'instruction': 1662, 'manual': 1663, 'alarm': 1664, 'clock': 1665, 'removing': 1666, 'antena': 1667, 'compared': 1668, 'state': 1669, 'allow': 1670, 'usage': 1671, 'ngage': 1672, 'earbuds': 1673, 'riingtones': 1674, 'rip': 1675, 'frequentyly': 1676, 'adhesive': 1677, 'practically': 1678, 'add': 1679, 'boost': 1680, 'concrete': 1681, 'knock': 1682, 'wood': 1683, 'transformed': 1684, 'organizational': 1685, 'capability': 1686, 'vehicle': 1687, 'cradle': 1688, 'jerks': 1689, 'los': 1690, 'angeles': 1691, 'starter': 1692, 'loudspeaker': 1693, 'option': 1694, 'bumpers': 1695, 'lights': 1696, 'improve': 1697, 'leaks': 1698, 'according': 1699, 'called': 1700, 'applifies': 1701, 'specially': 1702, 'transmission': 1703, 's11': 1704, 'finished': 1705, 'drivng': 1706, 'reverse': 1707, 'tape': 1708, 'embarassing': 1709, 'hurt': 1710, 'protects': 1711, 'operates': 1712, 'soyo': 1713, 'portraits': 1714, 'exterior': 1715, 'mentioned': 1716, 'gadgets': 1717, 'magical': 1718, 'comparably': 1719, 'offering': 1720, 'encourage': 1721, 'effective': 1722, 'recieve': 1723, 'cradles': 1724, 'kits': 1725, 'excelent': 1726, 'cingulair': 1727, 'nicer': 1728, 'era': 1729, 'colored': 1730, 'hoursthe': 1731, 'thereplacement': 1732, '2000': 1733, 'cheaply': 1734, 'distorted': 1735, 'yell': 1736, 'forgot': 1737, 'iriver': 1738, 'spinn': 1739, 'fond': 1740, 'magnetic': 1741, 'strap': 1742, 'psyched': 1743, 'appointments': 1744, 'appearance': 1745, 'sanyo': 1746, 'survived': 1747, 'dozens': 1748, 'blacktop': 1749, 'ill': 1750, 'earphones': 1751, 'finds': 1752, 'enter': 1753, 'modest': 1754, 'cellular': 1755, 'awsome': 1756, 'drained': 1757, 'earpad': 1758, 'displeased': 1759, 'defect': 1760, 'risk': 1761, 'built': 1762, 'restored': 1763, 'jx': 1764, 'searched': 1765, 'pad': 1766, 'lit': 1767, 'portable': 1768, 'colleague': 1769, 'fully': 1770, 'bed': 1771, 'wi': 1772, 'fi': 1773, 'morning': 1774, 'card': 1775, 'hat': 1776, 'timely': 1777, 'shipment': 1778, 'surefire': 1779, 'gx2': 1780, 'bt50': 1781, 'buyers': 1782, 'remorse': 1783, 'accessoryone': 1784, 'inexcusable': 1785, 'carriers': 1786, 'tmobile': 1787, 'procedure': 1788, 'motorolas': 1789, 'vx9900': 1790, 'env': 1791, 'rocketed': 1792, 'destination': 1793, 'unknown': 1794, 'conditions': 1795, 'usefulness': 1796, \"verizon's\": 1797, 'bills': 1798, 'plans': 1799, 'overnight': 1800, 'regret': 1801, 'pitiful': 1802, 'respect': 1803, 'stuck': 1804, 'max': 1805, 'mute': 1806, 'hybrid': 1807, 'palmtop': 1808, 'excels': 1809, 'roles': 1810, 'bt250v': 1811, 'bose': 1812, 'cancelling': 1813, 'commuter': 1814, 'photo': 1815, 'ad': 1816, 'earlier': 1817, 'noted': 1818, 'happens': 1819, 'frog': 1820, 'eye': 1821, 'pushed': 1822, 'function': 1823, 'aluminum': 1824, 'vx': 1825, 'protected': 1826, 'handheld': 1827, 'tools': 1828, 'sturdiness': 1829, 'source': 1830, 'waterproof': 1831, 'sliding': 1832, 'edge': 1833, 'pants': 1834, 'pockets': 1835, 'ugly': 1836, 'shield': 1837, 'incrediable': 1838, 'improvement': 1839, 'refuse': 1840, 'activate': 1841, 'gentle': 1842, 'threw': 1843, 'window': 1844, 'inches': 1845, 'counter': 1846, 'cracked': 1847, 'laughing': 1848, 'trunk': 1849, 'carried': 1850, 'hitch': 1851, 'practical': 1852, 'channel': 1853, 'directly': 1854, 'increase': 1855, 'shifting': 1856, 'bubbling': 1857, 'peeling': 1858, 'scratch': 1859, 'droid': 1860, 'exercise': 1861, 'frustration': 1862, 'earset': 1863, 'outgoing': 1864, 'package': 1865, 'understanding': 1866, 'patient': 1867, 'wirefly': 1868, 'contact': 1869, 'inform': 1870, 'practice': 1871, 'aggravating': 1872, 'virgin': 1873, 'muddy': 1874, 'casing': 1875, \"wire's\": 1876, 'insert': 1877, 'glued': 1878, 'slid': 1879, 'plantronincs': 1880, 'continues': 1881, 'flawed': 1882, 'disapointing': 1883, 'fourth': 1884, 'fixes': 1885, 'accessing': 1886, 'downloading': 1887, 'performing': 1888, 'functions': 1889, 'constantly': 1890, 'happening': 1891, 'adapters': 1892, 'procedures': 1893, 're': 1894, 'wiping': 1895, 'strength': 1896, 'plays': 1897, 'louder': 1898, 'navigate': 1899, 'recessed': 1900, 'avoiding': 1901, 'smoking': 1902, 'linked': 1903, 'possesed': 1904, 'trash': 1905, 'research': 1906, 'development': 1907, 'division': 1908, 'knows': 1909, 'infuriating': 1910, 'walkman': 1911, 'charges': 1912, 'europe': 1913, 'asia': 1914, 'clipping': 1915, 'deffinitely': 1916, \"cent's\": 1917, 'behing': 1918, '5020': 1919, 'comfortible': 1920, '24': 1921, 'pain': 1922, 'arrival': 1923, 'fraction': 1924, 'crappy': 1925, 'e715': 1926, 'seeen': 1927, 'interface': 1928, 'decade': 1929, 'compete': 1930, 'designs': 1931, '700w': 1932, 'transceiver': 1933, 'steer': 1934, 'genuine': 1935, 'replacementr': 1936, 'pens': 1937, 'buyit': 1938, 'beats': 1939, 'fingers': 1940, 'steep': 1941, 'normally': 1942, 'haul': 1943, 'dissapointing': 1944, 'originally': 1945, 'discarded': 1946, 'players': 1947, 'posted': 1948, 'detailed': 1949, 'comments': 1950, 'grey': 1951, 'existing': 1952, 'cds': 1953, 'currently': 1954, 'shooters': 1955, 'delay': 1956, 'messes': 1957, 'bitpim': 1958, 'program': 1959, 'transfer': 1960, 'accessory': 1961, 'manufacturer': 1962, 'muffled': 1963, 'incoming': 1964, 'severe': 1965, 'resistant': 1966, 'overly': 1967, 'contacted': 1968, 'produce': 1969, 'receipt': 1970, 'linksys': 1971, 'exchange': 1972, 'refurb': 1973, 'snug': 1974, 'heavy': 1975, 'keeps': 1976, 'utter': 1977, 'promised': 1978, 'loop': 1979, 'latch': 1980, 'visor': 1981, 'address': 1982, 'reboots': 1983, 'tungsten': 1984, 'e2': 1985, 'flipphones': 1986, 'designed': 1987, 'smoothly': 1988, 'study': 1989, 'interested': 1990, 'sins': 1991, 'industrial': 1992, 'tracking': 1993, 'detachable': 1994, 'periodically': 1995, 'upload': 1996, 'locks': 1997, 'screens': 1998, 'randomly': 1999, 'locked': 2000, '325': 2001, 'worn': 2002, 'ringer': 2003, 'choices': 2004, 'acceptable': 2005, 'balance': 2006, 'ready': 2007, 'upbeat': 2008, 'forgeries': 2009, 'abound': 2010, 'explain': 2011, 'jack': 2012, 'ca': 2013, '42': 2014, 'smallest': 2015, 'stays': 2016, 'drains': 2017, 'superfast': 2018, 'ergonomic': 2019, 'theory': 2020, 'stand': 2021, 'clips': 2022, 'occupied': 2023, 'distracting': 2024, 'except': 2025, 'cbr': 2026, 'mp3s': 2027, 'preferably': 2028, 'windows': 2029, 'media': 2030, 'sos': 2031, 'signals': 2032, 'connect': 2033, 'mini': 2034, 'near': 2035, 'open': 2036, 'allowing': 2037, 'startac': 2038, 'regretted': 2039, 'outperform': 2040, 'china': 2041, 'v325i': 2042, 'numbers': 2043, 'sim': 2044, '3o': 2045, 'r': 2046, 'crashed': 2047, 'replaced': 2048, '18': 2049, '4s': 2050, 'connecting': 2051, 'sources': 2052, 'imac': 2053, 'external': 2054, 'bells': 2055, 'whistles': 2056, 'slide': 2057, 'grip': 2058, 'prevents': 2059, 'slipping': 2060, 'span': 2061, 'exclaim': 2062, 'whoa': 2063, 'tv': 2064, 'corded': 2065, 'freedom': 2066, 'mark': 2067, 'shows': 2068, 'functional': 2069, 'soft': 2070, 'tight': 2071, 'shape': 2072, 'copier': 2073, 'sent': 2074, 'anywhere': 2075, 'sold': 2076, 'units': 2077, 'krussel': 2078, 'tracfonewebsite': 2079, 'toactivate': 2080, 'texas': 2081, 'dit': 2082, '5320': 2083, 'mainly': 2084, 'whatever': 2085, 'blueant': 2086, 'supertooth': 2087, 'pcs': 2088, 'sch': 2089, 'r450': 2090, 'slider': 2091, 'premium': 2092, 'plugs': 2093, 'plenty': 2094, 'capacity': 2095, 'confortable': 2096, 'periods': 2097, 'ant': 2098, 'hey': 2099, 'pleasantly': 2100, 'suprised': 2101, 'dustpan': 2102, 'indoors': 2103, 'disposable': 2104, 'puff': 2105, 'ride': 2106, 'smoother': 2107, 'nano': 2108, 'dissapointed': 2109, 'reccommend': 2110, 'carries': 2111, 'highest': 2112, 'anti': 2113, 'glare': 2114, 'smartphone': 2115, 'wont': 2116, 'atleast': 2117, 'addition': 2118, 'amp': 2119, 'reoccure': 2120, 'somewhere': 2121, 'creaks': 2122, 'wooden': 2123, 'floor': 2124, 'apartment': 2125, 'generally': 2126, 'inconspicuous': 2127, 'slowly': 2128, 'impossible': 2129, 'upgrade': 2130, 'securly': 2131, 'possibility': 2132, 'booking': 2133, 'entertainment': 2134, 'communication': 2135, 'activesync': 2136, 'optimal': 2137, 'synchronization': 2138, 'coupon': 2139, 'instance': 2140, 'ps3': 2141, 'cheapy': 2142, 'shouting': 2143, 'telephone': 2144, 'yes': 2145, 'shiny': 2146, 'grtting': 2147, '44': 2148, 'v3c': 2149, 'exceeds': 2150, 'sight': 2151, 'improper': 2152, 'effects': 2153, 'palms': 2154, 'hoped': 2155, 'father': 2156, 'v265': 2157, 'pads': 2158, 'stops': 2159, 'intermittently': 2160, 'reaching': 2161, 'row': 2162, 'keys': 2163, 'nightmare': 2164, 'describe': 2165, 'speakerphone': 2166, 'cassette': 2167, 'cellphones': 2168, 'planning': 2169, \"other's\": 2170, 'products': 2171, 'sensor': 2172, 'reliability': 2173, 'beeping': 2174, 'dieing': 2175, 'ir': 2176, 'cancellation': 2177, 'counterfeit': 2178, 'travled': 2179, 'swivel': 2180, 'sister': 2181, 'dual': 2182, '8125': 2183, 'keeping': 2184, 'bottowm': 2185, 'gimmick': 2186, 'opens': 2187, 'causing': 2188, 'discomfort': 2189, 'trust': 2190, 'maintains': 2191, 'flawless': 2192, 'devices': 2193, 'utterly': 2194, 'confusing': 2195, 'holder': 2196, 'cutouts': 2197, 'land': 2198, 'loops': 2199, 'material': 2200, 'flaws': 2201, 'owning': 2202, 'official': 2203, 'oem': 2204, 'loudest': 2205, 'competitors': 2206, 'saved': 2207, 'alot': 2208, 'cuts': 2209, 'unintelligible': 2210, 'restart': 2211, 'bend': 2212, 'leaf': 2213, 'metal': 2214, 'stress': 2215, 'leopard': 2216, 'print': 2217, 'wonderfully': 2218, 'wild': 2219, 'saggy': 2220, 'floppy': 2221, 'looses': 2222, 'snap': 2223, '8525': 2224, 'carry': 2225, 'fliptop': 2226, 'loose': 2227, 'wobbly': 2228, 'eventually': 2229, 'receive': 2230, 'fulfills': 2231, 'requirements': 2232, 'rests': 2233, 'against': 2234, 'websites': 2235, 'cables': 2236, 'lap': 2237, 'controls': 2238, 'accessable': 2239, 'mine': 2240, 'satisifed': 2241, '2005': 2242, 's710a': 2243, 'specs': 2244, 'armband': 2245, 'allot': 2246, 'clearer': 2247, 'keypads': 2248, 'reach': 2249, 'ericson': 2250, 'z500a': 2251, 'motor': 2252, 'control': 2253, 'center': 2254, 'voltage': 2255, 'humming': 2256, 'equipment': 2257, 'certain': 2258, 'girl': 2259, 'wake': 2260, 'styling': 2261, 'restocking': 2262, 'fee': 2263, 'darn': 2264, 'lousy': 2265, 'sweetest': 2266, 'securely': 2267, 'hook': 2268, 'directed': 2269, 'canal': 2270, 'unsatisfactory': 2271, 'videos': 2272, 'negatively': 2273, 'adapter': 2274, 'provide': 2275, 'hype': 2276, 'assumed': 2277, 'lense': 2278, 'falls': 2279, 'text': 2280, 'messaging': 2281, 'tricky': 2282, 'painful': 2283, 'lasted': 2284, 'blew': 2285, 'flops': 2286, 'smudged': 2287, 'touches': 2288, 'infra': 2289, 'port': 2290, 'irda': 2291, 'bank': 2292, 'holiday': 2293, 'rick': 2294, 'steve': 2295, 'angry': 2296, 'honeslty': 2297, 'ahead': 2298, 'warmer': 2299, 'wayyy': 2300, 'cape': 2301, 'cod': 2302, 'ravoli': 2303, 'chickenwith': 2304, 'cranberry': 2305, 'disgusted': 2306, 'shocked': 2307, 'indicate': 2308, 'cash': 2309, 'burrittos': 2310, 'blah': 2311, 'interior': 2312, 'velvet': 2313, 'cake': 2314, 'ohhh': 2315, 'hole': 2316, 'street': 2317, 'luke': 2318, 'sever': 2319, 'combos': 2320, '23': 2321, 'final': 2322, 'blow': 2323, 'accident': 2324, 'grab': 2325, 'pub': 2326, 'redeeming': 2327, 'hiro': 2328, 'drag': 2329, 'melted': 2330, 'styrofoam': 2331, 'fear': 2332, 'positive': 2333, 'pucks': 2334, 'disgust': 2335, 'register': 2336, 'rib': 2337, 'section': 2338, 'generic': 2339, 'firehouse': 2340, 'refreshing': 2341, 'pink': 2342, 'chow': 2343, 'mein': 2344, 'imaginative': 2345, 'lined': 2346, 'strings': 2347, 'banana': 2348, 'petrified': 2349, 'struggle': 2350, 'wave': 2351, 'receives': 2352, 'cocktails': 2353, 'handmade': 2354, \"we'd\": 2355, 'military': 2356, 'dos': 2357, 'gringos': 2358, 'tastings': 2359, 'jeff': 2360, 'milkshake': 2361, 'chocolate': 2362, 'milk': 2363, 'excalibur': 2364, 'common': 2365, 'sense': 2366, 'appalling': 2367, 'cheated': 2368, 'experiencing': 2369, 'relationship': 2370, 'parties': 2371, 'smelled': 2372, 'trap': 2373, 'turkey': 2374, 'pan': 2375, 'cakes': 2376, 'raving': 2377, 'disaster': 2378, 'tailored': 2379, 'palate': 2380, 'ratio': 2381, 'tenders': 2382, 'unsatisfying': 2383, 'omelets': 2384, 'summary': 2385, 'largely': 2386, 'sexy': 2387, 'outrageously': 2388, 'flirting': 2389, 'hottest': 2390, 'rock': 2391, 'casino': 2392, 'step': 2393, 'forward': 2394, 'bone': 2395, 'bloddy': 2396, \"mary's\": 2397, 'mussels': 2398, 'reduction': 2399, 'buffets': 2400, 'tigerlilly': 2401, 'afternoon': 2402, 'personable': 2403, 'sooooo': 2404, \"let's\": 2405, 'yama': 2406, '40min': 2407, 'arriving': 2408, 'actual': 2409, 'blandest': 2410, 'cuisine': 2411, 'worries': 2412, 'guys': 2413, 'loving': 2414, \"he's\": 2415, 'venture': 2416, 'further': 2417, 'host': 2418, 'lack': 2419, 'bitches': 2420, 'liking': 2421, 'reasons': 2422, 'reviewing': 2423, 'phenomenal': 2424, 'venturing': 2425, 'penne': 2426, 'vodka': 2427, 'including': 2428, 'massive': 2429, 'meatloaf': 2430, 'lox': 2431, 'capers': 2432, 'meet': 2433, 'weekend': 2434, 'suggestions': 2435, 'bamboo': 2436, 'shoots': 2437, 'blanket': 2438, 'moz': 2439, 'subpar': 2440, 'attention': 2441, 'ignore': 2442, 'fianc': 2443, 'middle': 2444, 'mandalay': 2445, 'forty': 2446, 'vain': 2447, 'crostini': 2448, 'highlights': 2449, 'nigiri': 2450, 'flavored': 2451, 'voodoo': 2452, 'gluten': 2453, 'leftover': 2454, 'relocated': 2455, 'diverse': 2456, 'hella': 2457, 'salty': 2458, 'spinach': 2459, 'avocado': 2460, 'ingredients': 2461, 'handed': 2462, 'listed': 2463, 'waitresses': 2464, 'lordy': 2465, 'khao': 2466, 'soi': 2467, 'terrific': 2468, 'thrilled': 2469, 'accommodations': 2470, 'daughter': 2471, 'caught': 2472, 'judging': 2473, 'inspired': 2474, 'leaves': 2475, 'desired': 2476, 'modern': 2477, 'maintaining': 2478, 'coziness': 2479, 'weekly': 2480, 'haunt': 2481, 'asking': 2482, 'verge': 2483, 'dressed': 2484, 'rudely': 2485, 'hits': 2486, 'quantity': 2487, 'lemon': 2488, 'raspberry': 2489, 'cocktail': 2490, 'imagined': 2491, 'crepe': 2492, 'bits': 2493, 'missing': 2494, \"joey's\": 2495, 'voted': 2496, 'readers': 2497, 'magazine': 2498, 'fridays': 2499, 'blows': 2500, 'exceeding': 2501, 'dreamed': 2502, 'serivce': 2503, 'inviting': 2504, 'lived': 2505, '1979': 2506, 'foot': 2507, 'mixed': 2508, 'mushrooms': 2509, 'yukon': 2510, 'corn': 2511, 'beateous': 2512, 'showed': 2513, 'climbing': 2514, 'tartar': 2515, 'jamaican': 2516, 'mojitos': 2517, 'rich': 2518, 'accordingly': 2519, 'rinse': 2520, 'nude': 2521, 'bussell': 2522, 'sprouts': 2523, 'risotto': 2524, 'hopefully': 2525, 'bodes': 2526, 'wrapped': 2527, 'dates': 2528, 'unbelievable': 2529, 'otto': 2530, 'welcome': 2531, 'mains': 2532, 'uninspired': 2533, 'whenever': 2534, \"world's\": 2535, 'annoying': 2536, 'drunk': 2537, 'patty': 2538, 'uploaded': 2539, 'yeah': 2540, 'sporting': 2541, 'events': 2542, 'walls': 2543, \"tv's\": 2544, \"they'd\": 2545, 'descriptions': 2546, 'eel': 2547, 'sauces': 2548, 'hardest': 2549, \"m's\": 2550, 'supposed': 2551, 'rolled': 2552, 'eyes': 2553, 'providing': 2554, 'flavourful': 2555, 'freezing': 2556, 'reviewer': 2557, 'delights': 2558, 'ayce': 2559, 'lighting': 2560, 'mood': 2561, 'based': 2562, 'gratitude': 2563, \"owner's\": 2564, 'privileged': 2565, 'parents': 2566, 'silently': 2567, 'peanut': 2568, \"would've\": 2569, 'godfathers': 2570, 'tough': 2571, 'recall': 2572, 'exquisite': 2573, 'thus': 2574, 'visited': 2575, 'proclaimed': 2576, 'wildly': 2577, 'veggitarian': 2578, 'platter': 2579, 'madison': 2580, 'ironman': 2581, 'chefs': 2582, 'dedicated': 2583, 'spots': 2584, 'jenni': 2585, 'goat': 2586, 'skimp': 2587, 'mac': 2588, 'stinks': 2589, 'burned': 2590, 'saganaki': 2591, 'disagree': 2592, 'fellow': 2593, 'yelpers': 2594, 'prepared': 2595, 'writing': 2596, 'noodles': 2597, 'chip': 2598, 'count': 2599, 'box': 2600, 'boring': 2601, 'greedy': 2602, 'corporation': 2603, 'dime': 2604, 'atrocious': 2605, 'charming': 2606, 'outdoor': 2607, 'english': 2608, 'muffin': 2609, 'untoasted': 2610, 'bus': 2611, 'figured': 2612, 'publicly': 2613, 'loudly': 2614, 'bbq': 2615, 'lighter': 2616, 'public': 2617, 'ways': 2618, 'downside': 2619, 'shawarrrrrrma': 2620, 'eyed': 2621, 'peas': 2622, 'unreal': 2623, 'vinaigrette': 2624, '00': 2625, 'honor': 2626, 'hut': 2627, 'coupons': 2628, 'unbelievably': 2629, 'covers': 2630, 'replenished': 2631, 'plain': 2632, 'yucky': 2633, '17': 2634, 'delicioso': 2635, 'spaghetti': 2636, 'tucson': 2637, 'chipotle': 2638, 'succulent': 2639, 'baseball': 2640, 'app': 2641, 'genuinely': 2642, 'enthusiastic': 2643, 'sadly': 2644, 'gordon': 2645, \"ramsey's\": 2646, 'shall': 2647, 'sharply': 2648, 'offered': 2649, 'handling': 2650, 'rowdy': 2651, 'despicable': 2652, 'craving': 2653, 'ache': 2654, 'ball': 2655, 'space': 2656, 'elegantly': 2657, 'customize': 2658, 'usual': 2659, 'bean': 2660, 'outta': 2661, 'inconsiderate': 2662, 'hi': 2663, 'dinners': 2664, 'outshining': 2665, 'halibut': 2666, 'starving': 2667, '90': 2668, 'disgrace': 2669, 'def': 2670, 'ethic': 2671, 'andddd': 2672, 'past': 2673, 'located': 2674, 'crystals': 2675, 'shopping': 2676, 'aria': 2677, 'summarize': 2678, 'nay': 2679, 'transcendant': 2680, 'brings': 2681, 'pneumatic': 2682, 'condiment': 2683, 'dispenser': 2684, 'ians': 2685, 'kiddos': 2686, 'bouchon': 2687, 'accountant': 2688, 'screwed': 2689, 'reminds': 2690, 'shops': 2691, 'san': 2692, 'francisco': 2693, 'buldogis': 2694, 'gourmet': 2695, 'frustrated': 2696, 'petty': 2697, 'iced': 2698, 'hungry': 2699, 'teeth': 2700, 'sore': 2701, 'companions': 2702, 'ground': 2703, 'smeared': 2704, 'tracked': 2705, 'pile': 2706, 'bird': 2707, 'poop': 2708, 'furthermore': 2709, 'operation': 2710, 'expert': 2711, 'connisseur': 2712, 'topic': 2713, 'jerk': 2714, 'strike': 2715, 'wants': 2716, 'rushed': 2717, 'across': 2718, 'appetizer': 2719, 'absolutley': 2720, '5lb': 2721, '4ths': 2722, 'gristle': 2723, 'fat': 2724, 'steiners': 2725, 'dollars': 2726, 'fs': 2727, 'pears': 2728, 'almonds': 2729, 'spicier': 2730, 'prefer': 2731, 'ribeye': 2732, 'mesquite': 2733, 'gooodd': 2734, 'connoisseur': 2735, 'difference': 2736, 'contained': 2737, 'mouthful': 2738, 'enjoyable': 2739, 'relaxed': 2740, 'venue': 2741, 'couples': 2742, 'groups': 2743, 'nargile': 2744, 'tater': 2745, 'southwest': 2746, 'vanilla': 2747, 'smooth': 2748, 'profiterole': 2749, 'choux': 2750, 'pastry': 2751, 'az': 2752, \"carly's\": 2753, 'forgetting': 2754, 'ventilation': 2755, 'upgrading': 2756, 'letdown': 2757, 'camelback': 2758, 'shop': 2759, 'cartel': 2760, 'trimmed': 2761, '70': 2762, 'claimed': 2763, 'handled': 2764, 'beautifully': 2765, 'jewel': 2766, 'las': 2767, 'limited': 2768, 'boiled': 2769, 'toro': 2770, 'tartare': 2771, 'cavier': 2772, 'extraordinary': 2773, 'thinly': 2774, 'wagyu': 2775, 'truffle': 2776, 'attached': 2777, 'gas': 2778, 'sign': 2779, 'decide': 2780, 'humiliated': 2781, 'worker': 2782, 'name': 2783, 'callings': 2784, 'conclusion': 2785, 'daily': 2786, 'specials': 2787, 'tragedy': 2788, 'struck': 2789, 'pancake': 2790, 'crawfish': 2791, 'monster': 2792, \"mom's\": 2793, 'multi': 2794, 'grain': 2795, 'pumpkin': 2796, 'pecan': 2797, 'fluffy': 2798, 'airline': 2799, 'noca': 2800, 'gyro': 2801, 'lettuce': 2802, 'thoroughly': 2803, 'pastas': 2804, 'cheesecurds': 2805, 'typical': 2806, 'glance': 2807, 'finger': 2808, 'beauty': 2809, 'greasy': 2810, 'unhealthy': 2811, 'similarly': 2812, 'man': 2813, 'apology': 2814, 'tiramisu': 2815, 'cannoli': 2816, 'sun': 2817, 'meats': 2818, 'frenchman': 2819, 'martini': 2820, 'opinion': 2821, 'gc': 2822, 'sample': 2823, 'thirty': 2824, 'vacant': 2825, 'yellowtail': 2826, 'carpaccio': 2827, 'strangers': 2828, 'hello': 2829, 'donut': 2830, 'saving': 2831, 'disgraceful': 2832, 'suffers': 2833, 'greens': 2834, 'hearts': 2835, 'hankering': 2836, 'forth': 2837, 'consider': 2838, 'theft': 2839, 'eew': 2840, 'complete': 2841, 'overhaul': 2842, 'witnessed': 2843, 'guests': 2844, 'regularly': 2845, 'swung': 2846, 'deeply': 2847, 'efficient': 2848, 'sucker': 2849, 'olives': 2850, 'perpared': 2851, 'giant': 2852, 'slices': 2853, 'dusted': 2854, 'powdered': 2855, 'sugar': 2856, 'fo': 2857, 'accomodate': 2858, 'vegan': 2859, 'veggie': 2860, 'crumby': 2861, 'pale': 2862, 'croutons': 2863, \"it'll\": 2864, 'trips': 2865, 'crema': 2866, 'caf': 2867, 'expanded': 2868, 'miss': 2869, 'philadelphia': 2870, 'north': 2871, 'scottsdale': 2872, 'soooooo': 2873, 'freaking': 2874, 'papers': 2875, 'reheated': 2876, 'wedges': 2877, 'absolute': 2878, 'tongue': 2879, 'cheek': 2880, 'bloody': 2881, 'mary': 2882, 'businesses': 2883, 'yellow': 2884, 'saffron': 2885, 'seasoning': 2886, 'grandmother': 2887, 'ignored': 2888, 'hostess': 2889, 'myself': 2890, 'boys': 2891, 'shirt': 2892, 'drastically': 2893, 'caesar': 2894, 'madhouse': 2895, 'proven': 2896, 'greatest': 2897, 'moods': 2898, 'macarons': 2899, 'insanely': 2900, 'informative': 2901, \"weren't\": 2902, 'deliver': 2903, 'plater': 2904, 'relax': 2905, 'sit': 2906, 'screams': 2907, \"somethat's\": 2908, 'duo': 2909, 'violinists': 2910, 'requested': 2911, 'personally': 2912, 'baklava': 2913, 'falafels': 2914, 'baba': 2915, 'ganoush': 2916, 'mgm': 2917, 'courteous': 2918, 'eclectic': 2919, 'onion': 2920, 'rings': 2921, 'nobu': 2922, 'google': 2923, 'smashburger': 2924, 'lover': 2925, 'gem': 2926, 'plantains': 2927, 'spends': 2928, 'themselves': 2929, 'panna': 2930, 'cotta': 2931, 'flavors': 2932, 'slaw': 2933, 'drenched': 2934, 'piano': 2935, 'soundtrack': 2936, 'rge': 2937, 'fillet': 2938, 'relleno': 2939, 'sergeant': 2940, 'auju': 2941, 'hawaiian': 2942, 'breeze': 2943, 'mango': 2944, 'magic': 2945, 'pineapple': 2946, 'smoothies': 2947, 'mortified': 2948, 'anyways': 2949, 'dripping': 2950, '2007': 2951, 'hospitality': 2952, 'industry': 2953, 'paradise': 2954, 'refrained': 2955, 'recommending': 2956, 'cibo': 2957, 'mean': 2958, 'famous': 2959, 'mouths': 2960, 'bellies': 2961, 'reminded': 2962, 'dough': 2963, 'tonight': 2964, 'elk': 2965, 'hooked': 2966, 'classics': 2967, 'sorely': 2968, 'quaint': 2969, 'deliciously': 2970, 'dylan': 2971, 'tummy': 2972, 'gratuity': 2973, 'larger': 2974, 'apple': 2975, 'han': 2976, 'nan': 2977, \"ryan's\": 2978, 'edinburgh': 2979, 'revisiting': 2980, 'naan': 2981, 'pine': 2982, 'nut': 2983, 'touched': 2984, 'airport': 2985, 'speedy': 2986, 'calligraphy': 2987, 'stood': 2988, 'begin': 2989, 'awkwardly': 2990, 'opened': 2991, 'guest': 2992, 'extensive': 2993, 'wide': 2994, 'array': 2995, 'inflate': 2996, 'smaller': 2997, 'grow': 2998, 'rapidly': 2999, 'lil': 3000, 'fuzzy': 3001, 'wontons': 3002, 'thick': 3003, 'level': 3004, 'spice': 3005, 'whelm': 3006, 'main': 3007, 'older': 3008, '30s': 3009, 'arepas': 3010, 'jalapeno': 3011, 'shoe': 3012, 'block': 3013, 'fancy': 3014, 'affordable': 3015, 'sour': 3016, 'soups': 3017, 'sunday': 3018, 'traditional': 3019, 'hunan': 3020, 'flair': 3021, 'bartenders': 3022, 'nutshell': 3023, 'restaraunt': 3024, 'smells': 3025, 'sewer': 3026, \"girlfriend's\": 3027, 'veal': 3028, 'satifying': 3029, 'join': 3030, 'club': 3031, 'email': 3032, 'colder': 3033, 'describing': 3034, 'tepid': 3035, 'chains': 3036, 'words': 3037, 'crowds': 3038, 'juries': 3039, 'lawyers': 3040, 'court': 3041, 'arrives': 3042, 'paying': 3043, '85': 3044, \"kid's\": 3045, 'wienerschnitzel': 3046, 'classic': 3047, 'maine': 3048, 'roll': 3049, 'brother': 3050, 'law': 3051, 'hereas': 3052, 'event': 3053, 'held': 3054, 'pissd': 3055, 'surprise': 3056, 'golden': 3057, 'hopes': 3058, 'bruschetta': 3059, 'devine': 3060, 'employee': 3061, 'lastly': 3062, 'mozzarella': 3063, 'negligent': 3064, 'unwelcome': 3065, 'suggest': 3066, 'consistent': 3067, 'packed': 3068, 'seasonal': 3069, 'fruit': 3070, 'peach': 3071, 'officially': 3072, 'blown': 3073, 'containers': 3074, 'opposed': 3075, 'cramming': 3076, 'takeout': 3077, 'boxes': 3078, 'crpe': 3079, 'delicate': 3080, 'fair': 3081, 'kabuki': 3082, 'maria': 3083, 'article': 3084, 'spices': 3085, 'fucking': 3086, \"caballero's\": 3087, 'head': 3088, 'oysters': 3089, 'round': 3090, 'disbelief': 3091, 'qualified': 3092, 'version': 3093, 'foods': 3094, 'tolerance': 3095, 'polite': 3096, 'wash': 3097, 'biscuit': 3098, 'coconut': 3099, 'fella': 3100, 'huevos': 3101, 'rancheros': 3102, 'wines': 3103, 'pricey': 3104, 'temp': 3105, 'prepare': 3106, 'bare': 3107, 'gloves': 3108, 'deep': 3109, 'oil': 3110, 'pleasure': 3111, 'plethora': 3112, 'sandwiches': 3113, 'seal': 3114, 'approval': 3115, 'college': 3116, 'cooking': 3117, 'class': 3118, 'editing': 3119, 'besides': 3120, \"costco's\": 3121, 'highlighted': 3122, 'unique': 3123, 'grocery': 3124, 'japanese': 3125, 'dude': 3126, 'doughy': 3127, 'inch': 3128, 'wire': 3129, 'ourselves': 3130, 'albondigas': 3131, 'tomato': 3132, 'meatballs': 3133, 'occasions': 3134, 'medium': 3135, 'bloodiest': 3136, 'anymore': 3137, 'chai': 3138, 'latte': 3139, 'allergy': 3140, 'warnings': 3141, 'clue': 3142, 'contain': 3143, 'peanuts': 3144, 'mediterranean': 3145, 'beers': 3146, 'highlight': 3147, 'concern': 3148, 'mellow': 3149, 'mushroom': 3150, 'strawberry': 3151, 'unprofessional': 3152, 'loyal': 3153, 'patron': 3154, 'occasional': 3155, 'pats': 3156, 'bellagio': 3157, 'anticipated': 3158, 'correct': 3159, 'sals': 3160, 'fav': 3161, 'unexperienced': 3162, 'employees': 3163, 'chickens': 3164, 'heads': 3165, 'steakhouse': 3166, 'concept': 3167, 'guacamole': 3168, 'pured': 3169, 'postinos': 3170, 'poisoning': 3171, 'batch': 3172, 'thinking': 3173, 'yay': 3174, 'hilarious': 3175, 'eve': 3176, 'remember': 3177, 'caring': 3178, 'teamwork': 3179, 'degree': 3180, 'ri': 3181, 'calamari': 3182, 'fondue': 3183, 'scene': 3184, \"denny's\": 3185, 'downright': 3186, 'waaaaaayyyyyyyyyy': 3187, 'sangria': 3188, 'glass': 3189, 'ridiculous': 3190, 'brisket': 3191, 'trippy': 3192, 'hurry': 3193, 'reservation': 3194, 'stretch': 3195, 'imagination': 3196, 'cashew': 3197, 'chipolte': 3198, 'ranch': 3199, 'dipping': 3200, 'sause': 3201, 'watered': 3202, 'workers': 3203, 'douchey': 3204, 'indoor': 3205, 'garden': 3206, 'con': 3207, 'spotty': 3208, 'ensued': 3209, 'apologize': 3210, 'fill': 3211, 'binge': 3212, 'drinking': 3213, 'carbs': 3214, 'insults': 3215, 'profound': 3216, 'deuchebaggery': 3217, 'solidify': 3218, \"don't'\": 3219, 'combo': 3220, 'ala': 3221, 'cart': 3222, 'blame': 3223, 'rave': 3224, 'del': 3225, 'avoided': 3226, 'hamburger': 3227, 'hell': 3228, \"ya'all\": 3229, 'fireball': 3230, 'disapppointment': 3231, 'correction': 3232, 'heimer': 3233, 'putting': 3234, 'cause': 3235, 'vomited': 3236, 'circumstances': 3237, 'tops': 3238, 'brownish': 3239, 'movies': 3240, 'ha': 3241, 'flop': 3242, '99': 3243, 'bigger': 3244, 'unwrapped': 3245, 'mile': 3246, 'brushfire': 3247, \"hasn't\": 3248, 'closed': 3249, 'mirage': 3250, 'refried': 3251, 'dried': 3252, 'crusty': 3253, 'caterpillar': 3254, 'appetite': 3255, 'instantly': 3256, 'ninja': 3257, \"hadn't\": 3258, 'poured': 3259, 'wound': 3260, 'drawing': 3261}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(reviews)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))\n",
    "print(word_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vfh0WGmKWyjI"
   },
   "source": [
    "# Generate sequences for the reviews\n",
    "Generate a sequence for each review. Set the max length to match the longest review. Add the padding zeros at the end of the review for reviews that are not as long as the longest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VwyqBS2nV53o",
    "outputId": "d0cbc426-9e79-4748-962a-abf4bf1fc20e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1992, 139)\n",
      "So there is no way for me to plug it in here in the US unless I go by a converter.\n",
      "[  28   59    8   56  142   13   61    7  269    6   15   46   15    2\n",
      "  149  449    4   60  113    5 1429    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(reviews)\n",
    "padded_sequences = pad_sequences(sequences, padding='post')\n",
    "\n",
    "# What is the shape of the vector containing the padded sequences?\n",
    "# The shape shows the number of sequences and the length of each one.\n",
    "print(padded_sequences.shape)\n",
    "\n",
    "# What is the first review?\n",
    "print (reviews[0])\n",
    "\n",
    "# Show the sequence for the first review\n",
    "print(padded_sequences[0])\n",
    "\n",
    "# Try printing the review and padded sequence for other elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XIG52aKPdpux"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pazU5OmxehIA"
   },
   "source": [
    "## Get the dataset\n",
    "\n",
    "We're going to use a dataset containing Amazon and Yelp reviews, with their related sentiment (1 for positive, 0 for negative). This dataset was originally extracted from [here](https://www.kaggle.com/marklvl/sentiment-labelled-sentences-data-set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpwQT2E9ez5B",
    "outputId": "0f3a0e1e-a79a-4250-d192-8390cb41290a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-10 04:59:43--  https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\n",
      "Resolving drive.google.com (drive.google.com)... 173.194.218.100, 173.194.218.101, 173.194.218.102, ...\n",
      "Connecting to drive.google.com (drive.google.com)|173.194.218.100|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-08-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nvvjfic227ft7c9c8r0ecm67tolhndif/1676005125000/11118900490791463723/*/13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P?uuid=963e7a67-b54c-4e75-b687-980e0e5e86ee [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2023-02-10 04:59:44--  https://doc-08-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nvvjfic227ft7c9c8r0ecm67tolhndif/1676005125000/11118900490791463723/*/13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P?uuid=963e7a67-b54c-4e75-b687-980e0e5e86ee\n",
      "Resolving doc-08-ak-docs.googleusercontent.com (doc-08-ak-docs.googleusercontent.com)... 74.125.134.132, 2607:f8b0:400c:c00::84\n",
      "Connecting to doc-08-ak-docs.googleusercontent.com (doc-08-ak-docs.googleusercontent.com)|74.125.134.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 127831 (125K) [text/csv]\n",
      "Saving to: /tmp/sentiment.csv\n",
      "\n",
      "/tmp/sentiment.csv  100%[===================>] 124.83K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-02-10 04:59:44 (116 MB/s) - /tmp/sentiment.csv saved [127831/127831]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    -O /tmp/sentiment.csv https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6Zvp9NScfMnw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('/tmp/sentiment.csv')\n",
    "\n",
    "sentences = dataset['text'].tolist()\n",
    "labels = dataset['sentiment'].tolist()\n",
    "\n",
    "# Separate out the sentences and labels into training and test sets\n",
    "training_size = int(len(sentences) * 0.8)\n",
    "\n",
    "training_sentences = sentences[0:training_size]\n",
    "testing_sentences = sentences[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "\n",
    "# Make labels into numpy arrays for use with the network later\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHpvqaSigcST"
   },
   "source": [
    "## Tokenize the dataset\n",
    "\n",
    "Tokenize the dataset, including padding and OOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "78icewYRgfxh"
   },
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "embedding_dim = 16\n",
    "max_length = 100\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, padding=padding_type, \n",
    "                       truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences,maxlen=max_length, \n",
    "                               padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4yIEk_8kszh"
   },
   "source": [
    "## Review a Sequence\n",
    "\n",
    "Let's quickly take a look at one of the padded sequences to ensure everything above worked appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTU3FmVGk100",
    "outputId": "4b0c103e-0987-42d3-d4b1-e21ac036665f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good case excellent value ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "Good case Excellent value.\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(padded[1]))\n",
    "print(training_sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RI91liJnlA92"
   },
   "source": [
    "## Train a Basic Sentiment Model with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bBMgzp-_lMTp",
    "outputId": "3ad7ccf2-e928-41da-9caf-05da30b08a82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 16)           16000     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 9606      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,613\n",
      "Trainable params: 25,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a basic sentiment network\n",
    "# Note the embedding layer is first, \n",
    "# and the output is only 1 node as it is either 0 or 1 (negative or positive)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pfl1W-zVldpn",
    "outputId": "40805ae4-abc9-4832-cf59-8e95455dfa18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 2s 12ms/step - loss: 0.6927 - accuracy: 0.5173 - val_loss: 0.6978 - val_accuracy: 0.4110\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5229 - val_loss: 0.7008 - val_accuracy: 0.4110\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6780 - accuracy: 0.5738 - val_loss: 0.6834 - val_accuracy: 0.5363\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.7514 - val_loss: 0.6346 - val_accuracy: 0.7143\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.8186 - val_loss: 0.5715 - val_accuracy: 0.7444\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8964 - val_loss: 0.5439 - val_accuracy: 0.7218\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.9165 - val_loss: 0.4823 - val_accuracy: 0.7719\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2427 - accuracy: 0.9416 - val_loss: 0.4671 - val_accuracy: 0.7769\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.9561 - val_loss: 0.4659 - val_accuracy: 0.7619\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9680 - val_loss: 0.4736 - val_accuracy: 0.7694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f95403218e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model.fit(padded, training_labels_final, epochs=num_epochs, validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjMZ4ZFQl_48"
   },
   "source": [
    "## Get files for visualizing the network\n",
    "\n",
    "The code below will download two files for visualizing how your network \"sees\" the sentiment related to each word. Head to http://projector.tensorflow.org/ and load these files, then click the \"Sphereize\" checkbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S2lB46FirAVx",
    "outputId": "67bd25d9-d848-44e5-eb83-5fa3afbe817d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 16)\n"
     ]
    }
   ],
   "source": [
    "# First get the weights of the embedding layer\n",
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xcha0oGemHX2"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Write out the embedding vectors and metadata\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for word_num in range(1, vocab_size):\n",
    "  word = reverse_word_index[word_num]\n",
    "  embeddings = weights[word_num]\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-Q6ALywmWVz"
   },
   "outputs": [],
   "source": [
    "# Download the files\n",
    "try:\n",
    "  from google.colab import files\n",
    "except ImportError:\n",
    "  pass\n",
    "else:\n",
    "  files.download('vecs.tsv')\n",
    "  files.download('meta.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNoxfY-i3Ir1"
   },
   "source": [
    "## Predicting Sentiment in New Reviews\n",
    "\n",
    "Now that you've trained and visualized your network, take a look below at how we can predict sentiment in new reviews the network has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXtfw-OY3WoZ",
    "outputId": "74fc9858-3194-4d57-ed97-5e7d0d2e3f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I love this phone', 'I hate spaghetti', 'Everything was cold', 'Everything was hot exactly as I wanted', 'Everything was green', 'the host seated us immediately', 'they gave us free chocolate cake', 'not sure about the wilted flowers on the table', 'only works when I stand on tippy toes', 'does not work when I stand on my head']\n",
      "\n",
      "HOT OFF THE PRESS! HERE ARE SOME NEWLY MINTED, ABSOLUTELY GENUINE REVIEWS!\n",
      "\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "I love this phone\n",
      "[0.97937185]\n",
      "\n",
      "\n",
      "I hate spaghetti\n",
      "[0.08169074]\n",
      "\n",
      "\n",
      "Everything was cold\n",
      "[0.47374475]\n",
      "\n",
      "\n",
      "Everything was hot exactly as I wanted\n",
      "[0.6973145]\n",
      "\n",
      "\n",
      "Everything was green\n",
      "[0.5684528]\n",
      "\n",
      "\n",
      "the host seated us immediately\n",
      "[0.7062718]\n",
      "\n",
      "\n",
      "they gave us free chocolate cake\n",
      "[0.8673687]\n",
      "\n",
      "\n",
      "not sure about the wilted flowers on the table\n",
      "[0.04739018]\n",
      "\n",
      "\n",
      "only works when I stand on tippy toes\n",
      "[0.9337003]\n",
      "\n",
      "\n",
      "does not work when I stand on my head\n",
      "[0.00238234]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict a review   \n",
    "fake_reviews = ['I love this phone', 'I hate spaghetti', \n",
    "                'Everything was cold',\n",
    "                'Everything was hot exactly as I wanted', \n",
    "                'Everything was green', \n",
    "                'the host seated us immediately',\n",
    "                'they gave us free chocolate cake', \n",
    "                'not sure about the wilted flowers on the table',\n",
    "                'only works when I stand on tippy toes', \n",
    "                'does not work when I stand on my head']\n",
    "\n",
    "print(fake_reviews) \n",
    "\n",
    "# Create the sequences\n",
    "padding_type='post'\n",
    "sample_sequences = tokenizer.texts_to_sequences(fake_reviews)\n",
    "fakes_padded = pad_sequences(sample_sequences, padding=padding_type, maxlen=max_length)           \n",
    "\n",
    "print('\\nHOT OFF THE PRESS! HERE ARE SOME NEWLY MINTED, ABSOLUTELY GENUINE REVIEWS!\\n')              \n",
    "\n",
    "classes = model.predict(fakes_padded)\n",
    "\n",
    "# The closer the class is to 1, the more positive the review is deemed to be\n",
    "for x in range(len(fake_reviews)):\n",
    "  print(fake_reviews[x])\n",
    "  print(classes[x])\n",
    "  print('\\n')\n",
    "\n",
    "# Try adding reviews of your own\n",
    "# Add some negative words (such as \"not\") to the good reviews and see what happens\n",
    "# For example:\n",
    "# they gave us free chocolate cake and did not charge us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XG8jm81BFN9w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CH5gnvxl-N3U"
   },
   "source": [
    "# What's in a (sub)word?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaId3I3WFOyd"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l09c06_nlp_subwords.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l09c06_nlp_subwords.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykxAKKa1Dl0s"
   },
   "source": [
    "In this colab, we'll work with subwords, or words made up of the pieces of larger words, and see how that impacts our network and related embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQCr_NAT-g5w"
   },
   "source": [
    "## Import TensorFlow and related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Q8Wa_ZlX-mPH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRHk-4Te-yLJ"
   },
   "source": [
    "## Get the original dataset\n",
    "\n",
    "We'll once again use the dataset containing Amazon and Yelp reviews. This dataset was originally extracted from [here](https://www.kaggle.com/marklvl/sentiment-labelled-sentences-data-set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XJAxrOLi-02C",
    "outputId": "93b8ddbb-6408-4e9c-a2f3-9c0c07c090f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-10 06:48:24--  https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P\n",
      "Resolving drive.google.com (drive.google.com)... 173.194.217.102, 173.194.217.138, 173.194.217.100, ...\n",
      "Connecting to drive.google.com (drive.google.com)|173.194.217.102|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-08-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/obm4tifg0at841cslb1v9jb5dpcsq48k/1676011650000/11118900490791463723/*/13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P?uuid=25820f49-ee2d-41d8-b193-e5a09189baa6 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2023-02-10 06:48:25--  https://doc-08-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/obm4tifg0at841cslb1v9jb5dpcsq48k/1676011650000/11118900490791463723/*/13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P?uuid=25820f49-ee2d-41d8-b193-e5a09189baa6\n",
      "Resolving doc-08-ak-docs.googleusercontent.com (doc-08-ak-docs.googleusercontent.com)... 108.177.13.132, 2607:f8b0:400c:c09::84\n",
      "Connecting to doc-08-ak-docs.googleusercontent.com (doc-08-ak-docs.googleusercontent.com)|108.177.13.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 127831 (125K) [text/csv]\n",
      "Saving to: /tmp/sentiment.csv\n",
      "\n",
      "/tmp/sentiment.csv  100%[===================>] 124.83K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2023-02-10 06:48:25 (82.8 MB/s) - /tmp/sentiment.csv saved [127831/127831]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://drive.google.com/uc?id=13ySLC_ue6Umt9RJYSeM2t-V0kCv-4C-P \\\n",
    "    -O /tmp/sentiment.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Dr-EDUKP_HBl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv('/tmp/sentiment.csv')\n",
    "\n",
    "# Just extract out sentences and labels first - we will create subwords here\n",
    "sentences = dataset['text'].tolist()\n",
    "labels = dataset['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zut9Wng_R3B"
   },
   "source": [
    "## Create a subwords dataset\n",
    "\n",
    "We can use the existing Amazon and Yelp reviews dataset with `tensorflow_datasets`'s `SubwordTextEncoder` functionality. `SubwordTextEncoder.build_from_corpus()` will create a tokenizer for us. You could also use this functionality to get subwords from a much larger corpus of text as well, but we'll just use our existing dataset here.\n",
    "\n",
    "The Amazon and Yelp dataset we are using isn't super large, so we'll create a subword `vocab_size` of only the 1,000 most common words, as well as cutting off each subword to be at most 5 characters.\n",
    "\n",
    "Check out the related documentation [here](https://www.tensorflow.org/datasets/api_docs/python/tfds/features/text/SubwordTextEncoder#build_from_corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "aElsgxia_43g"
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "vocab_size = 1000\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(sentences, vocab_size, max_subword_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XNZWGKqBDc3",
    "outputId": "b170fdbf-f4bf-4243-8567-0f337c9692af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have to jiggle the plug to get it to line up right to get decent volume.\n",
      "[4, 31, 6, 849, 162, 450, 12, 1, 600, 438, 775, 6, 175, 14, 6, 55, 213, 159, 474, 775, 6, 175, 614, 380, 295, 148, 72, 789]\n",
      "I \n",
      "have \n",
      "to \n",
      "j\n",
      "ig\n",
      "gl\n",
      "e \n",
      "the \n",
      "pl\n",
      "ug\n",
      " \n",
      "to \n",
      "get \n",
      "it \n",
      "to \n",
      "li\n",
      "ne \n",
      "up \n",
      "right\n",
      " \n",
      "to \n",
      "get \n",
      "dec\n",
      "ent \n",
      "vo\n",
      "lu\n",
      "me\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Check that the tokenizer works appropriately\n",
    "num = 5\n",
    "print(sentences[num])\n",
    "encoded = tokenizer.encode(sentences[num])\n",
    "print(encoded)\n",
    "# Separately print out each subword, decoded\n",
    "for i in encoded:\n",
    "  print(tokenizer.decode([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYnbqctXGKcC"
   },
   "source": [
    "## Replace sentence data with encoded subwords\n",
    "\n",
    "Now, we'll re-create the dataset to be used for training by actually encoding each of the individual sentences. This is equivalent to `text_to_sequences` with the `Tokenizer` we used in earlier exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rAmql34aGfeV"
   },
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "  sentences[i] = tokenizer.encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jNnee_csG5Iz",
    "outputId": "ca7c640b-9991-472c-c3a2-d6df2e987dee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[625, 677, 626, 274, 380, 633, 148, 844, 789]\n"
     ]
    }
   ],
   "source": [
    "# Check the sentences are appropriately replaced\n",
    "print(sentences[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpIigjecHVkF"
   },
   "source": [
    "## Final pre-processing\n",
    "\n",
    "Before training, we still need to pad the sequences, as well as split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "INIFSAcEHool"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_length = 50\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "\n",
    "# Pad all sentences\n",
    "sentences_padded = pad_sequences(sentences, maxlen=max_length, \n",
    "                                 padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "# Separate out the sentences and labels into training and test sets\n",
    "training_size = int(len(sentences) * 0.8)\n",
    "\n",
    "training_sentences = sentences_padded[0:training_size]\n",
    "testing_sentences = sentences_padded[training_size:]\n",
    "training_labels = labels[0:training_size]\n",
    "testing_labels = labels[training_size:]\n",
    "\n",
    "# Make labels into numpy arrays for use with the network later\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QC9A-sTpPPiL"
   },
   "source": [
    "## Train a Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDKcL64IPcfy",
    "outputId": "76740198-669a-4bad-c079-98224c4c6936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 50, 16)            16000     \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,109\n",
      "Trainable params: 16,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VqkMNtIeP3oz",
    "outputId": "df117ad2-fb5f-441a-ff5f-8fa8b1494ce7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 1s 8ms/step - loss: 0.6941 - accuracy: 0.4809 - val_loss: 0.6948 - val_accuracy: 0.4110\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5248 - val_loss: 0.6940 - val_accuracy: 0.4110\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.6121 - val_loss: 0.6897 - val_accuracy: 0.6441\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6842 - accuracy: 0.7250 - val_loss: 0.6817 - val_accuracy: 0.7243\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6730 - accuracy: 0.7633 - val_loss: 0.6693 - val_accuracy: 0.7318\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.7389 - val_loss: 0.6509 - val_accuracy: 0.7318\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.6348 - accuracy: 0.7696 - val_loss: 0.6312 - val_accuracy: 0.7293\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.7765 - val_loss: 0.6141 - val_accuracy: 0.7393\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.7954 - val_loss: 0.5980 - val_accuracy: 0.7644\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5626 - accuracy: 0.8079 - val_loss: 0.5797 - val_accuracy: 0.7694\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.8380 - val_loss: 0.5679 - val_accuracy: 0.7820\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5136 - accuracy: 0.8506 - val_loss: 0.5581 - val_accuracy: 0.7794\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.8625 - val_loss: 0.5483 - val_accuracy: 0.7820\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.8638 - val_loss: 0.5383 - val_accuracy: 0.7794\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8751 - val_loss: 0.5337 - val_accuracy: 0.7870\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 0.4326 - accuracy: 0.8927 - val_loss: 0.5308 - val_accuracy: 0.7794\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.4154 - accuracy: 0.8989 - val_loss: 0.5297 - val_accuracy: 0.7719\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.3999 - accuracy: 0.9040 - val_loss: 0.5264 - val_accuracy: 0.7744\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.3846 - accuracy: 0.9083 - val_loss: 0.5223 - val_accuracy: 0.7794\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.3720 - accuracy: 0.9159 - val_loss: 0.5213 - val_accuracy: 0.7794\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.9184 - val_loss: 0.5224 - val_accuracy: 0.7694\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.9266 - val_loss: 0.5229 - val_accuracy: 0.7920\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.9272 - val_loss: 0.5279 - val_accuracy: 0.7619\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.9341 - val_loss: 0.5270 - val_accuracy: 0.7644\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.9347 - val_loss: 0.5299 - val_accuracy: 0.7619\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.9397 - val_loss: 0.5337 - val_accuracy: 0.7594\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.9441 - val_loss: 0.5375 - val_accuracy: 0.7569\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.9460 - val_loss: 0.5414 - val_accuracy: 0.7544\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2685 - accuracy: 0.9498 - val_loss: 0.5495 - val_accuracy: 0.7594\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.9485 - val_loss: 0.5512 - val_accuracy: 0.7444\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history = model.fit(training_sentences, training_labels_final, epochs=num_epochs, \n",
    "                    validation_data=(testing_sentences, testing_labels_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj18M42kQkCi"
   },
   "source": [
    "## Visualize the Training Graph\n",
    "\n",
    "We can visualize the training graph below again. Does there appear to be a difference in how validation accuracy and loss is trending compared to with full words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "id": "uy8KIMPIQlvH",
    "outputId": "51b5d7da-390a-4169-9839-da8048af7b72"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "  plt.plot(history.history[string])\n",
    "  plt.plot(history.history['val_'+string])\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(string)\n",
    "  plt.legend([string, 'val_'+string])\n",
    "  plt.show()\n",
    "  \n",
    "plot_graphs(history, \"accuracy\")\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_m7QzouQQ1Rs"
   },
   "source": [
    "## Get files for visualizing the network\n",
    "\n",
    "Once again, you can visualize the sentiment related to all of the subwords using the below code and by heading to http://projector.tensorflow.org/ to upload and view the data.\n",
    "\n",
    "Note that the below code does have a few small changes to handle the different way text is encoded in our dataset compared to before with the built in `Tokenizer`.\n",
    "\n",
    "You may get an error like \"Number of tensors (999) do not match the number of lines in metadata (992).\" As long as you load the vectors first without error and wait a few seconds after this pops up, you will be able to click outside the file load menu and still view the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dezs4wE5RMQu"
   },
   "outputs": [],
   "source": [
    "# First get the weights of the embedding layer\n",
    "e = model.layers[0]\n",
    "weights = e.get_weights()[0]\n",
    "print(weights.shape) # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LXKqy9Z1RSmt"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# Write out the embedding vectors and metadata\n",
    "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for word_num in range(0, vocab_size - 1):\n",
    "  word = tokenizer.decode([word_num])\n",
    "  embeddings = weights[word_num]\n",
    "  out_m.write(word + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v04wBMybRoGx"
   },
   "outputs": [],
   "source": [
    "# Download the files\n",
    "try:\n",
    "  from google.colab import files\n",
    "except ImportError:\n",
    "  pass\n",
    "else:\n",
    "  files.download('vecs.tsv')\n",
    "  files.download('meta.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-RbzrJEFOLQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
